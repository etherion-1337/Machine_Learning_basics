{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Library: TensorFlow 2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run this from tf env, with tensorflow 2.0+**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Introduction\n",
    "\n",
    "Tensorflow is an open-source library for graph-based numerical computation.     \n",
    "Has both low and high level APIs.       \n",
    "Can be used to perform addition, multiplication and differentiation.      \n",
    "Can be used to train ML models.       \n",
    "\n",
    "Important changes in TensorFlow 2.0:        \n",
    "Eager exucution is now enabled y default, which allows users to write simpler and more intuitive code.       \n",
    "Modeling building is now centered around the Keras and Estimators high-level APIs.         \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=5, shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0D Tensor\n",
    "d0 = tf.ones((1,))\n",
    "d0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=8, shape=(2,), dtype=float32, numpy=array([1., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1D Tensor\n",
    "d1 = tf.ones((2,))\n",
    "d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=11, shape=(2, 2), dtype=float32, numpy=\n",
       "array([[1., 1.],\n",
       "       [1., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2D Tensor\n",
    "d2 = tf.ones((2,2))\n",
    "d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=14, shape=(2, 2, 2), dtype=float32, numpy=\n",
       "array([[[1., 1.],\n",
       "        [1., 1.]],\n",
       "\n",
       "       [[1., 1.],\n",
       "        [1., 1.]]], dtype=float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3D Tensor\n",
    "d3 = tf.ones((2,2,2))\n",
    "d3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[1. 1.]\n",
      "  [1. 1.]]]\n"
     ]
    }
   ],
   "source": [
    "# Print the 3D tensor\n",
    "print(d3.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1 Defining constants in TensorFlow\n",
    "\n",
    "A constant is the simplest category of tensor.      \n",
    "A constant does not change and cannot be trained.      \n",
    "\n",
    "It can, however, have any dimension.      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import constant\n",
    "\n",
    "# Define a 2x3 constant tensor of 3s.\n",
    "a = constant(3, shape=[2,3])\n",
    "\n",
    "# define a 2x2 tensor, which is constructed from the 1D tensor: 1,2,3,4\n",
    "b = constant([1,2,3,4],shape=[2,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 3 3]\n",
      " [3 3 3]]\n",
      "[[1 2]\n",
      " [3 4]]\n"
     ]
    }
   ],
   "source": [
    "print(a.numpy())\n",
    "print(b.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3]\n",
      "[[0. 0.]\n",
      " [0. 0.]]\n",
      "[[0 0]\n",
      " [0 0]]\n",
      "[[1. 1.]\n",
      " [1. 1.]]\n",
      "[[1 1]\n",
      " [1 1]]\n",
      "[[7 7 7]\n",
      " [7 7 7]\n",
      " [7 7 7]]\n"
     ]
    }
   ],
   "source": [
    "# some convenient way of defining constant\n",
    "input_tensor = constant([1,2,3,4],shape=[2,2])\n",
    "\n",
    "a = tf.constant([1,2,3])\n",
    "\n",
    "b = tf.zeros([2,2])\n",
    "\n",
    "c = tf.zeros_like(input_tensor)\n",
    "\n",
    "d = tf.ones([2,2])\n",
    "\n",
    "e = tf. ones_like(input_tensor)\n",
    "\n",
    "f = tf.fill([3,3],7)\n",
    "\n",
    "print(a.numpy())\n",
    "print(b.numpy())\n",
    "print(c.numpy())\n",
    "print(d.numpy())\n",
    "print(e.numpy())\n",
    "print(f.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2 Defining and initialising variables\n",
    "\n",
    "Unlike a constant, a variable's value can change during computation. The value of a variable is shared, persistent and modifiable.         \n",
    "Its data type and shape are fixed.         \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a variable\n",
    "a0 = tf.Variable([1,2,3,4,5,6], dtype=tf.float32)\n",
    "a1 = tf.Variable([1,2,3,4,5,6], dtype=tf.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a constant\n",
    "b = tf.constant(2,tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute their product\n",
    "c0 = tf.multiply(a0,b)\n",
    "c1 = a0*b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.  4.  6.  8. 10. 12.]\n",
      "[ 2.  4.  6.  8. 10. 12.]\n"
     ]
    }
   ],
   "source": [
    "print(c0.numpy())\n",
    "print(c1.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining data as constants:        \n",
    "\n",
    "After you have imported constant, you will use it to transform a numpy array, credit_numpy, into a tensorflow constant, credit_constant. This array contains feature columns from a dataset on credit card holders and is previewed in the image below. We will return to this dataset in later chapters.             \n",
    "\n",
    "Note that tensorflow version 2.0 allows you to use data as either a numpy array or a tensorflow constant object. Using a constant will ensure that any operations performed with that object are done in tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_numpy = np.array([[ 2.0000e+00,  2.4000e+01,  1.0000e+00,  3.9130e+03],\n",
    "       [ 2.0000e+00,  2.6000e+01,  2.0000e+00,  2.6820e+03],\n",
    "       [ 2.0000e+00,  3.4000e+01,  2.0000e+00,  2.9239e+04],\n",
    "       [ 2.0000e+00,  3.7000e+01,  2.0000e+00,  3.5650e+03],\n",
    "       [ 3.0000e+00,  4.1000e+01,  1.0000e+00, -1.6450e+03],\n",
    "       [ 2.0000e+00,  4.6000e+01,  1.0000e+00,  4.7929e+04]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The datatype is: <dtype: 'float64'>\n",
      "The shape is: (6, 4)\n"
     ]
    }
   ],
   "source": [
    "# Import constant from TensorFlow\n",
    "from tensorflow import constant\n",
    "\n",
    "# Convert the credit_numpy array into a tensorflow constant\n",
    "credit_constant = constant(credit_numpy)\n",
    "\n",
    "# Print constant datatype\n",
    "print('The datatype is:', credit_constant.dtype)\n",
    "\n",
    "# Print constant shape\n",
    "print('The shape is:', credit_constant.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Operation of Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow has a model of computation that revolves around the use of graphs. A Tensorflow graph contains edges and nodes, where the edges are tensors and the modes are operations.      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The add() operation performs element-wise **addition** with two tensors.       \n",
    "Element-wise addition requires both tensors to have the same shape.            \n",
    "The add() operator is overloaded, which means that we can also perform addition using the plus symbol.      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3]\n",
      "[4 6]\n",
      "[[ 6  8]\n",
      " [10 12]]\n"
     ]
    }
   ],
   "source": [
    "# addition operator\n",
    "from tensorflow import constant, add\n",
    "\n",
    "# Define 0-dimensional tensors\n",
    "A0 = constant([1])\n",
    "B0 = constant([2])\n",
    "\n",
    "# Define 1-dimensional tensors\n",
    "A1 = constant([1,2])\n",
    "B1 = constant([3,4])\n",
    "\n",
    "# Define 2-dimensional tensors\n",
    "A2 = constant([[1,2],[3,4]])\n",
    "B2 = constant([[5,6],[7,8]])\n",
    "\n",
    "# Perform tensor addition with add()\n",
    "C0 = add(A0,B0) #scaler addition\n",
    "C1 = add(A1,B1) #vector addition\n",
    "C2 = add(A2,B2) #matrix addition\n",
    "\n",
    "print(C0.numpy())\n",
    "print(C1.numpy())\n",
    "print(C2.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Element-wise multiplication** performed using multiply() operation.        \n",
    "The tensors involved must have the same shape.     \n",
    "**Matrix multiplication** performed wutg matmul() operator.         \n",
    "The matmul(A,B) operation multiplies A by B.       \n",
    "Number of columns of A must equal to the number of rows of B.      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.]\n",
      "[[1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "[[1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import ones, matmul, multiply\n",
    "\n",
    "# Define tensors\n",
    "A0 = ones(1)\n",
    "A31 = ones([3,1])\n",
    "A34 = ones([3,4])\n",
    "A43 = ones([4,3])\n",
    "\n",
    "ex1 = multiply(A0,A0)\n",
    "ex2 = multiply(A31,A31)\n",
    "ex3 = multiply(A34,A34)\n",
    "\n",
    "print(ex1.numpy())\n",
    "print(ex2.numpy())\n",
    "print(ex3.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summing over tensor dimensions:          \n",
    "\n",
    "The reduce_sum() operator sums over the dimensions of a tensor.      \n",
    "reduce_sum(A) sums over all dimensions of A.      \n",
    "reduce_sum(A,i) sums over dimension i.       \n",
    "In each case we reduce the size of the tensor by summing over one of its dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]]]\n",
      "24.0\n",
      "[[2. 2. 2. 2.]\n",
      " [2. 2. 2. 2.]\n",
      " [2. 2. 2. 2.]]\n",
      "[[3. 3. 3. 3.]\n",
      " [3. 3. 3. 3.]]\n",
      "[[4. 4. 4.]\n",
      " [4. 4. 4.]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import ones, reduce_sum\n",
    "\n",
    "# Define a 2x3x4 tensors of ones\n",
    "A = ones([2,3,4])\n",
    "\n",
    "# Sum over all dimension\n",
    "B = reduce_sum(A)\n",
    "\n",
    "# Sum over dimension 0,1,2\n",
    "B0 = reduce_sum(A,0) # 3x4 matrix of 2s\n",
    "B1 = reduce_sum(A,1) # 2x4 matrix of 3s\n",
    "B2 = reduce_sum(A,2) # 2x3 matrix of 4s\n",
    "\n",
    "print(A.numpy())\n",
    "print(B.numpy())\n",
    "print(B0.numpy())\n",
    "print(B1.numpy())\n",
    "print(B2.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C1: [1 2 3 4]\n",
      "C23: [[1 2 3]\n",
      " [1 6 4]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import ones_like\n",
    "\n",
    "# Define tensors A1 and A23 as constants\n",
    "A1 = constant([1, 2, 3, 4])\n",
    "A23 = constant([[1, 2, 3], [1, 6, 4]])\n",
    "\n",
    "# Define B1 and B23 to have the correct shape\n",
    "B1 = ones_like(A1)\n",
    "B23 = ones_like(A23)\n",
    "\n",
    "# Perform element-wise multiplication\n",
    "C1 = multiply(A1,B1)\n",
    "C23 = multiply(A23,B23)\n",
    "\n",
    "# Print the tensors C1 and C23\n",
    "print('C1: {}'.format(C1.numpy()))\n",
    "print('C23: {}'.format(C23.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1687]\n",
      " [-3218]\n",
      " [-1933]\n",
      " [57850]]\n"
     ]
    }
   ],
   "source": [
    "# Define features, params, and bill as constants\n",
    "features = constant([[2, 24], [2, 26], [2, 57], [1, 37]])\n",
    "params = constant([[1000], [150]])\n",
    "bill = constant([[3913], [2682], [8617], [64400]])\n",
    "\n",
    "# Compute billpred using features and params\n",
    "billpred = matmul(features,params)\n",
    "\n",
    "# Compute and print the error\n",
    "error = bill - billpred\n",
    "print(error.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11 50]\n",
      " [ 7  2]\n",
      " [ 4 60]\n",
      " [ 3  0]\n",
      " [25 10]]\n",
      "172\n",
      "[ 50 122]\n",
      "[61  9 64  3 35]\n"
     ]
    }
   ],
   "source": [
    "wealth = constant([[11, 50], [7, 2], [4, 60], [3, 0],[25,10]])\n",
    "\n",
    "wealth_all = reduce_sum(wealth)\n",
    "# Sum over dimension 0,1\n",
    "wealth0 = reduce_sum(wealth,0) # 3x4 matrix of 2s\n",
    "wealth1 = reduce_sum(wealth,1) # 2x4 matrix of 3s\n",
    "\n",
    "\n",
    "print(wealth.numpy())\n",
    "print(wealth_all.numpy())\n",
    "print(wealth0.numpy())\n",
    "print(wealth1.numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Advanced operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gradient():         \n",
    "Computes the slope of a function at a point.       \n",
    "\n",
    "reshape():        \n",
    "Reshape a tensor (e.g. 10x10 to 100x1)         \n",
    "\n",
    "random():       \n",
    "Populates tensor with entries drawn.        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finding the optimum (gradient())**        \n",
    "\n",
    "In many ML problems, we will want to find the optimum of a funciton, e.g. minimise the loss function or maximise the objective function.        \n",
    "\n",
    "Minimum: lowest value of a loss function.          \n",
    "Maximum: highest value of objective function.           \n",
    "\n",
    "We can do this using the gradient() operation.      \n",
    "We start this process by passing points to the gradient operation until we find one where the gradient is 0, that is the **optimum**.        \n",
    "Minimum: change in gradient > 0.       \n",
    "Maximum: change in gradient < 0.          \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.0\n"
     ]
    }
   ],
   "source": [
    "# Define x\n",
    "x = tf.Variable(-1.0)\n",
    "\n",
    "# Define y to be x^2 wihtin instance of GradientTape\n",
    "# watch method to an instance of gradient tape and then pass the variable x,\n",
    "# this will allow us to compute the rate of change of y wrt x.\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(x)\n",
    "    y = tf.multiply(x,x)\n",
    "    \n",
    "# Evaluate the gradient of y at x = -1, using the tape instance of gradienttape\n",
    "g = tape.gradient(y,x)\n",
    "print(g.numpy())\n",
    "\n",
    "# slope is -2 at x = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Images as tensor (reshape())**        \n",
    "\n",
    "A grayscale image has a natural respresentation as matrix with values between 0 and 255. Some algorithm require us to reshape matrices into vectors before using them as inputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[221]\n",
      " [232]\n",
      " [206]\n",
      " [111]]\n",
      "[[105 109  38]\n",
      " [145 170 187]\n",
      " [ 94 225  87]\n",
      " [ 50 136 170]]\n"
     ]
    }
   ],
   "source": [
    "# generate grayscale image\n",
    "gray = tf.random.uniform([2,2],maxval=255, dtype=\"int32\")\n",
    "\n",
    "# reshape grayscale image\n",
    "gray = tf.reshape(gray, [2*2,1])\n",
    "\n",
    "print(gray.numpy())\n",
    "# generate a color image\n",
    "color = tf.random.uniform([2,2,3],maxval=255, dtype=\"int32\")\n",
    "\n",
    "# reshape color image\n",
    "color = tf.reshape(color,[2*2,3])\n",
    "print(color.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are given a loss function, y=x2, which you want to minimize. You can do this by computing the slope using the GradientTape() operation at different values of x. If the slope is positive, you can decrease the loss by lowering x. If it is negative, you can decrease it by increasing x. This is how gradient descent works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.0\n",
      "2.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "def compute_gradient(x0):\n",
    "  \t# Define x as a variable with an initial value of x0\n",
    "\tx = tf.Variable(x0)\n",
    "\twith tf.GradientTape() as tape:\n",
    "\t\ttape.watch(x)\n",
    "        # Define y using the multiply operation\n",
    "\t\ty = tf.multiply(x,x)\n",
    "    # Return the gradient of y with respect to x\n",
    "\treturn tape.gradient(y, x).numpy()\n",
    "\n",
    "# Compute and print gradients at x = -1, 1, and 0\n",
    "print(compute_gradient(-1.0))\n",
    "print(compute_gradient(1.0))\n",
    "print(compute_gradient(0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Linear Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Input data\n",
    "\n",
    "When we train a ML model, we will want to import data from an external source. Numeric data wil need to be assigned a type, and text and image data will need to be converted into a usable format.       \n",
    "\n",
    "External datasets can be imported using TensorFlow. It is useful for complex data pipeline. We can also use pandas to import data. And then we can convert data into numpy array, which we can use without further modification in TensorFlow.     \n",
    "Dataset will contain columns with different data types. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>...</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>7129300520</td>\n",
       "      <td>20141013T000000</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6414100192</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>2170</td>\n",
       "      <td>400</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5631500400</td>\n",
       "      <td>20150225T000000</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2487200875</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>910</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1954400510</td>\n",
       "      <td>20150218T000000</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id             date     price  bedrooms  bathrooms  sqft_living  \\\n",
       "0  7129300520  20141013T000000  221900.0         3       1.00         1180   \n",
       "1  6414100192  20141209T000000  538000.0         3       2.25         2570   \n",
       "2  5631500400  20150225T000000  180000.0         2       1.00          770   \n",
       "3  2487200875  20141209T000000  604000.0         4       3.00         1960   \n",
       "4  1954400510  20150218T000000  510000.0         3       2.00         1680   \n",
       "\n",
       "   sqft_lot  floors  waterfront  view  ...  grade  sqft_above  sqft_basement  \\\n",
       "0      5650     1.0           0     0  ...      7        1180              0   \n",
       "1      7242     2.0           0     0  ...      7        2170            400   \n",
       "2     10000     1.0           0     0  ...      6         770              0   \n",
       "3      5000     1.0           0     0  ...      7        1050            910   \n",
       "4      8080     1.0           0     0  ...      8        1680              0   \n",
       "\n",
       "   yr_built  yr_renovated  zipcode      lat     long  sqft_living15  \\\n",
       "0      1955             0    98178  47.5112 -122.257           1340   \n",
       "1      1951          1991    98125  47.7210 -122.319           1690   \n",
       "2      1933             0    98028  47.7379 -122.233           2720   \n",
       "3      1965             0    98136  47.5208 -122.393           1360   \n",
       "4      1987             0    98074  47.6168 -122.045           1800   \n",
       "\n",
       "   sqft_lot15  \n",
       "0        5650  \n",
       "1        7639  \n",
       "2        8062  \n",
       "3        5000  \n",
       "4        7503  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing = pd.read_csv(\"../Machine_Learning_basics/data/kc_house_data.csv\")\n",
    "housing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21613 entries, 0 to 21612\n",
      "Data columns (total 21 columns):\n",
      "id               21613 non-null int64\n",
      "date             21613 non-null object\n",
      "price            21613 non-null float64\n",
      "bedrooms         21613 non-null int64\n",
      "bathrooms        21613 non-null float64\n",
      "sqft_living      21613 non-null int64\n",
      "sqft_lot         21613 non-null int64\n",
      "floors           21613 non-null float64\n",
      "waterfront       21613 non-null int64\n",
      "view             21613 non-null int64\n",
      "condition        21613 non-null int64\n",
      "grade            21613 non-null int64\n",
      "sqft_above       21613 non-null int64\n",
      "sqft_basement    21613 non-null int64\n",
      "yr_built         21613 non-null int64\n",
      "yr_renovated     21613 non-null int64\n",
      "zipcode          21613 non-null int64\n",
      "lat              21613 non-null float64\n",
      "long             21613 non-null float64\n",
      "sqft_living15    21613 non-null int64\n",
      "sqft_lot15       21613 non-null int64\n",
      "dtypes: float64(5), int64(15), object(1)\n",
      "memory usage: 3.5+ MB\n"
     ]
    }
   ],
   "source": [
    "housing.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to numpy array\n",
    "housing_arr = np.array(housing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting data type with np array\n",
    "\n",
    "#convert price olumns to float32\n",
    "price = np.array(housing[\"price\"],np.float32)\n",
    "\n",
    "#convert waterfrount column to Boolean\n",
    "# waterfront is a np array after conversion\n",
    "waterfront = np.array(housing[\"waterfront\"], np.bool)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting data type using case in TensorFlow\n",
    "\n",
    "#convert price olumns to float32\n",
    "price = tf.cast(housing[\"price\"],tf.float32)\n",
    "\n",
    "#convert waterfrount column to Boolean\n",
    "# waterfront is tf.tensor type after conversion\n",
    "waterfront = tf.cast(housing[\"waterfront\"],tf.bool)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[221900. 538000. 180000. ... 402101. 400000. 325000.]\n",
      "tf.Tensor([False False False ... False False False], shape=(21613,), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "# Import numpy and tensorflow with their standard aliases\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Use a numpy array to define price as a 32-bit float\n",
    "price = np.array(housing['price'], np.float32)\n",
    "\n",
    "# Define waterfront as a Boolean using cast\n",
    "waterfront = tf.cast(housing['waterfront'], tf.bool)\n",
    "\n",
    "# Print price and waterfront\n",
    "print(price)\n",
    "print(waterfront)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Loss functions\n",
    "\n",
    "We need the loss funtion to train models because they tell us how well our model explains the data.     \n",
    "Measure of model fit: w/o this feedback, it is unclear how to adjust model parameters during the training process.     \n",
    "High loss value indicates that the model fit is poor: we typically want to minimise the loss function. (in some case we also might want to maximise a function instead). We can always place a minus sign before the function we want to maximize and instead minimise it.      \n",
    "\n",
    "TensorFlow has operations for common loss functions (for linear model):       \n",
    "1) Mean squared error (MSE)           \n",
    "2) Mean absolute error (MAE)        \n",
    "3) Huber error           \n",
    "\n",
    "Loss functions are accessible from tf.keras.losses():       \n",
    "tf.keras.losses.mse()         \n",
    "tf.keras.losses.mae()      \n",
    "tf.keras.losses.Huber()       \n",
    "\n",
    "MSE:       \n",
    "Strongly penalise outliers      \n",
    "High sensitivity near minimum       \n",
    "\n",
    "MAE:    \n",
    "Scales linearly with size of error      \n",
    "Low sensitity near minimum       \n",
    "\n",
    "Huber:    \n",
    "Similar to MSE near minimum      \n",
    "Similar to MAE away form minimum        \n",
    "\n",
    "For greater sensitivity near the minimum, use MSE or Huber.      \n",
    "To minimise the impact of outliers, use MAE or Huber.          \n",
    "\n",
    "In many cases, the training process will require us to supply a function that accepts our model's variables and ata and returns a loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a loss function\n",
    "\n",
    "# compute the MSE loss.\n",
    "# need two tensors to compute it: the actual values or target\n",
    "# predicted values or predictions\n",
    "\n",
    "loss = tf.keras.losses.mse(targets, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a linear regression model\n",
    "def linear_regression(intercept, slope = slope, features = features):\n",
    "    return intercept + features*slope\n",
    "\n",
    "# define a loss function ot compute the MSE\n",
    "def loss_function(intercept, slope, targets = targets, features = features):\n",
    "    # compute the predictions for a linear model\n",
    "    predictions = linear_regression(intercept, slope)\n",
    "    \n",
    "    # return the loss\n",
    "    return tf.keras.losses.mse(targets, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the loss for test data inputs\n",
    "loss_function(intercept, slope, test_targets, test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a variable named scalar\n",
    "scalar = tf.Variable(1.0, dtype=tf.float32)\n",
    "\n",
    "# Define the model\n",
    "def model(scalar, features = features):\n",
    "  \treturn scalar * features\n",
    "\n",
    "# Define a loss function\n",
    "def loss_function(scalar, features = features, targets = targets):\n",
    "\t# Compute the predicted values\n",
    "\tpredictions = model(scalar, features)\n",
    "    \n",
    "\t# Return the mean absolute error loss\n",
    "\treturn tf.keras.losses.mae(targets, predictions)\n",
    "\n",
    "# Evaluate the loss function and print the loss\n",
    "print(loss_function(scalar).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Linear Regression\n",
    "\n",
    "A linear regression model assumes a linear relationship (univariate regression):       \n",
    "price = intercept + size * slope + error (to predict house price with size of house)      \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "424840500000.0\n",
      "305881000000.0\n",
      "219757840000.0\n",
      "160266650000.0\n",
      "121212770000.0\n",
      "97023190000.0\n",
      "82984410000.0\n",
      "75397860000.0\n",
      "71600530000.0\n",
      "69847540000.0\n",
      "246.97383 253.7275\n"
     ]
    }
   ],
   "source": [
    "# Linear regression in TensorFlow\n",
    "\n",
    "# Define the targets and features\n",
    "price = np.array(housing[\"price\"],np.float32)\n",
    "size = np.array(housing[\"sqft_living\"],np.float32)\n",
    "\n",
    "# Define the intercept and slope, initialisation\n",
    "intercept = tf.Variable(0.1, dtype=np.float32)\n",
    "slope = tf.Variable(0.1, dtype=np.float32)\n",
    "\n",
    "# define a model: linear regression\n",
    "def linear_regression(intercept, slope, features = size):\n",
    "    return intercept + features*slope\n",
    "\n",
    "# compute the predicted and loss\n",
    "def loss_function(intercept, slope, targets = price, features = size):\n",
    "    predictions = linear_regression(intercept, slope)\n",
    "    return tf.keras.losses.mse(targets, predictions)\n",
    "\n",
    "# Define an optimisation operation\n",
    "# learning rate = 0.5\n",
    "opt = tf.keras.optimizers.Adam(0.5)\n",
    "\n",
    "# minimise the loss function and price the loss\n",
    "for j in range(1000):\n",
    "    opt.minimize(lambda: loss_function(intercept,slope), var_list=[intercept,slope])\n",
    "    if j % 100 == 0:\n",
    "\t    print(loss_function(intercept, slope).numpy())\n",
    "    \n",
    "# print the trained parameter\n",
    "print(intercept.numpy(), slope.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Batch training\n",
    "\n",
    "We can use batch training to handle large datasets.        \n",
    "\n",
    "If the dataset is much larger and we cannot fit the entire dataset in memory, we can instead divide it into batchs and train on those batches sequentially.        \n",
    "\n",
    "A single pass over all of the batch is called an epoch and the process itself is called batch training.      \n",
    "Batch trianing also allow us to update model weights and optimizer parameters after each batch, rather than at the end of the epoch.       \n",
    "\n",
    "pd.read_csv() allows us to load data in batches.      \n",
    "Avoid loading entire dataset.     \n",
    "We can do this by using the chunksize parameter to provide batch size.         \n",
    "\n",
    "Full sample:       \n",
    "1) One update per epoch         \n",
    "2) Accepts datasets w/o modification       \n",
    "3) Limited by memory      \n",
    "\n",
    "Batch Training:       \n",
    "1) Multiple updates per epoch       \n",
    "2) Requires division of dataset      \n",
    "3) No limit on dataset size          \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data in batches\n",
    "\n",
    "for batch in pd.read_csv(\"../Machine_Learning_basics/data/kc_house_data.csv\", chunksize=100):\n",
    "    #extract price column\n",
    "    price = np.array(batch[\"price\"],np.float32)\n",
    "    \n",
    "    #extract size column\n",
    "    size = np.array(batch[\"size\"],np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.31781912 0.29831016\n"
     ]
    }
   ],
   "source": [
    "# train a linear model in batches, minimumal example\n",
    "\n",
    "# Define trainable variable\n",
    "intercept = tf.Variable(0.1, dtype=np.float32)\n",
    "slope = tf.Variable(0.1,dtype=np.float32)\n",
    "\n",
    "# Define model\n",
    "def linear_regression(intercept, slope, features):\n",
    "    return intercept + features*slope\n",
    "\n",
    "# Compute predicted values and return loss function\n",
    "def loss_function(intercept, slope,targets,features):\n",
    "    predictions = linear_regression(intercept,slope,features)\n",
    "    return tf.keras.losses.mse(targets,predictions)\n",
    "\n",
    "# Define optimizer\n",
    "opt = tf.keras.optimizers.Adam()\n",
    "\n",
    "# load data in batches\n",
    "for batch in pd.read_csv(\"../Machine_Learning_basics/data/kc_house_data.csv\", chunksize=100):\n",
    "    #extract the target and feature columns\n",
    "    price_batch = np.array(batch[\"price\"],np.float32)\n",
    "    size_batch = np.array(batch[\"sqft_lot\"],np.float32)\n",
    "    \n",
    "    #minimize the loss function\n",
    "    opt.minimize(lambda: loss_function(intercept, slope, price_batch, size_batch),var_list=[intercept,slope])\n",
    "    \n",
    "print(intercept.numpy(),slope.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Neural Networks\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Dense layer\n",
    "\n",
    "Input layer consist of features. The output layer contains our prediction. Each hidden layer takes inputs form the previous layer, applies numerical weights to them, sum them together, and then applies an activation function.     \n",
    "\n",
    "Dense layer: applies weights to all nodes from the previous layer.      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define inputs (features)\n",
    "inputs = tf.constant([[1.0,35.0]]) # 2 input (feature) value (e.g. maritial status (1/0) and age)\n",
    "\n",
    "# Define weights\n",
    "weights = tf.Variable([[-0.5],[-0.01]])\n",
    "\n",
    "# Define bias\n",
    "# play a similar role to intercept in the linear regression model\n",
    "bias = tf.Variable([0.5])\n",
    "\n",
    "# A simple dense layer\n",
    "# multiply inputs (features) by the weights\n",
    "product = tf.matmul(inputs, weights)\n",
    "\n",
    "# Define dense layer\n",
    "# add the \"product\" to bias and apply non-linear transformation (sigmoid function, activation function)\n",
    "dense = tf.keras.activations.sigmoid(product+bias)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A complete model \n",
    "# using high level API Keras\n",
    "\n",
    "# Define input (features) layer\n",
    "inputs = tf.constant(data, tf.float32)\n",
    "\n",
    "# Define first dense layer\n",
    "# 10 outgoing nodes\n",
    "# by default, a bias will be included\n",
    "# inputs as arg to the first dens layer\n",
    "dense1 = tf.keras.layers.Dense(10,activation=\"sigmoid\")(inputs)\n",
    "\n",
    "# Define second dense layer\n",
    "dense2 = tf.keras.layers.Dense(5,activation=\"sigmoid\")(dense1)\n",
    "\n",
    "# Define output (predictions)\n",
    "outputs = tf.keras.layers.Dense(1,activation=\"sigmoid\")(dense2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "High-level approach:         \n",
    "Relies on complex operations in high-level APIs, such as Keras and Estimators, reducing the amount of code needed. The weights and the mathmatical operations will typically be hidden by the layer constructor.       \n",
    "\n",
    "Low-level approach:         \n",
    "Linear algebra       \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input layer contains 3 features -- education, marital status, and age -- which are available as borrower_features. The hidden layer contains 2 nodes and the output layer contains a single node.          \n",
    "\n",
    "For each layer, you will take the previous layer as an input, initialize a set of weights, compute the product of the inputs and weights, and then apply an activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " dense1's output shape: (1, 2)\n",
      "\n",
      " prediction: 0.9525741338729858\n",
      "\n",
      " actual: 1\n"
     ]
    }
   ],
   "source": [
    "borrower_features = np.array([[2.,  1., 24.]],dtype=np.float32)\n",
    "\n",
    "# Initialize bias1\n",
    "bias1 = tf.Variable(1.0)\n",
    "\n",
    "# Initialize weights1 as 3x2 variable of ones\n",
    "weights1 = tf.Variable(ones((3, 2)))\n",
    "\n",
    "# Perform matrix multiplication of borrower_features and weights1\n",
    "product1 = tf.matmul(borrower_features,weights1)\n",
    "\n",
    "# Apply sigmoid activation function to product1 + bias1\n",
    "dense1 = tf.keras.activations.sigmoid(product1 + bias1)\n",
    "\n",
    "# Print shape of dense1\n",
    "print(\"\\n dense1's output shape: {}\".format(dense1.shape))\n",
    "\n",
    "# Initialize bias2 and weights2\n",
    "bias2 = tf.Variable(1.0)\n",
    "weights2 = tf.Variable(ones((2, 1)))\n",
    "\n",
    "# Perform matrix multiplication of dense1 and weights2\n",
    "product2 = tf.matmul(dense1,weights2)\n",
    "\n",
    "# Apply activation to product2 + bias2 and print the prediction\n",
    "prediction = tf.keras.activations.sigmoid(product2 + bias2)\n",
    "print('\\n prediction: {}'.format(prediction.numpy()[0,0]))\n",
    "print('\\n actual: 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " shape of borrower_features:  (5, 3)\n",
      "\n",
      " shape of weights1:  (3, 2)\n",
      "\n",
      " shape of bias1:  (1,)\n",
      "\n",
      " shape of dense1:  (5, 2)\n"
     ]
    }
   ],
   "source": [
    "weights1 = np.array(\n",
    "       [[-0.6 ,  0.6 ],\n",
    "       [ 0.8 , -0.3 ],\n",
    "       [-0.09, -0.08]],dtype=np.float32)\n",
    "\n",
    "borrower_features = np.array(\n",
    "       [[ 3.,  3., 23.],\n",
    "       [ 2.,  1., 24.],\n",
    "       [ 1.,  1., 49.],\n",
    "       [ 1.,  1., 49.],\n",
    "       [ 2.,  1., 29.]],dtype=np.float32)\n",
    "\n",
    "bias1 = np.array([0.1], dtype=np.float32)\n",
    "# Compute the product of borrower_features and weights1\n",
    "products1 = tf.matmul(borrower_features,weights1)\n",
    "\n",
    "# Apply a sigmoid activation function to products1 + bias1\n",
    "dense1 = tf.keras.activations.sigmoid(products1+bias1)\n",
    "\n",
    "# Print the shapes of borrower_features, weights1, bias1, and dense1\n",
    "print('\\n shape of borrower_features: ', borrower_features.shape)\n",
    "print('\\n shape of weights1: ', weights1.shape)\n",
    "print('\\n shape of bias1: ', bias1.shape)\n",
    "print('\\n shape of dense1: ', dense1.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've now seen how to define dense layers in tensorflow using linear algebra. In this exercise, we'll skip the linear algebra and let keras work out the details. This will allow us to construct the network below, which has 2 hidden layers and 10 features, using less code than we needed for the network with 1 hidden layer and 3 features.       \n",
    "\n",
    "To construct this network, we'll need to define three dense layers, each of which takes the previous layer as an input, multiplies it by weights, and applies an activation function. Note that input data has been defined and is available as a 100x10 tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " shape of dense1:  (100, 7)\n",
      "\n",
      " shape of dense2:  (100, 3)\n",
      "\n",
      " shape of predictions:  (100, 1)\n"
     ]
    }
   ],
   "source": [
    "borrower_features = np.array([[6.96469188e-01, 2.86139339e-01, 2.26851448e-01, 5.51314771e-01,\n",
    "        7.19468951e-01, 4.23106462e-01, 9.80764210e-01, 6.84829712e-01,\n",
    "        4.80931908e-01, 3.92117530e-01],\n",
    "       [3.43178004e-01, 7.29049683e-01, 4.38572258e-01, 5.96778952e-02,\n",
    "        3.98044258e-01, 7.37995386e-01, 1.82491735e-01, 1.75451756e-01,\n",
    "        5.31551361e-01, 5.31827569e-01],\n",
    "       [6.34400964e-01, 8.49431813e-01, 7.24455297e-01, 6.11023486e-01,\n",
    "        7.22443402e-01, 3.22958916e-01, 3.61788660e-01, 2.28263229e-01,\n",
    "        2.93714046e-01, 6.30976140e-01],\n",
    "       [9.21049416e-02, 4.33701187e-01, 4.30862755e-01, 4.93685097e-01,\n",
    "        4.25830305e-01, 3.12261224e-01, 4.26351309e-01, 8.93389165e-01,\n",
    "        9.44160044e-01, 5.01836658e-01],\n",
    "       [6.23952925e-01, 1.15618393e-01, 3.17285478e-01, 4.14826214e-01,\n",
    "        8.66309166e-01, 2.50455379e-01, 4.83034253e-01, 9.85559762e-01,\n",
    "        5.19485116e-01, 6.12894535e-01],\n",
    "       [1.20628662e-01, 8.26340795e-01, 6.03060126e-01, 5.45068026e-01,\n",
    "        3.42763841e-01, 3.04120779e-01, 4.17022198e-01, 6.81300759e-01,\n",
    "        8.75456870e-01, 5.10422349e-01],\n",
    "       [6.69313788e-01, 5.85936546e-01, 6.24903500e-01, 6.74689054e-01,\n",
    "        8.42342436e-01, 8.31949860e-02, 7.63682842e-01, 2.43666381e-01,\n",
    "        1.94222957e-01, 5.72456956e-01],\n",
    "       [9.57125202e-02, 8.85326803e-01, 6.27248943e-01, 7.23416328e-01,\n",
    "        1.61292069e-02, 5.94431877e-01, 5.56785166e-01, 1.58959642e-01,\n",
    "        1.53070509e-01, 6.95529521e-01],\n",
    "       [3.18766415e-01, 6.91970289e-01, 5.54383278e-01, 3.88950586e-01,\n",
    "        9.25132513e-01, 8.41669977e-01, 3.57397556e-01, 4.35914621e-02,\n",
    "        3.04768085e-01, 3.98185670e-01],\n",
    "       [7.04958856e-01, 9.95358467e-01, 3.55914861e-01, 7.62547791e-01,\n",
    "        5.93176901e-01, 6.91701770e-01, 1.51127458e-01, 3.98876280e-01,\n",
    "        2.40855902e-01, 3.43456000e-01],\n",
    "       [5.13128161e-01, 6.66624546e-01, 1.05908483e-01, 1.30894944e-01,\n",
    "        3.21980596e-01, 6.61564350e-01, 8.46506238e-01, 5.53257346e-01,\n",
    "        8.54452491e-01, 3.84837806e-01],\n",
    "       [3.16787899e-01, 3.54264677e-01, 1.71081826e-01, 8.29112649e-01,\n",
    "        3.38670850e-01, 5.52370071e-01, 5.78551471e-01, 5.21533072e-01,\n",
    "        2.68806447e-03, 9.88345444e-01],\n",
    "       [9.05341566e-01, 2.07635865e-01, 2.92489409e-01, 5.20010173e-01,\n",
    "        9.01911378e-01, 9.83630896e-01, 2.57542074e-01, 5.64359069e-01,\n",
    "        8.06968689e-01, 3.94370049e-01],\n",
    "       [7.31073022e-01, 1.61069021e-01, 6.00698590e-01, 8.65864456e-01,\n",
    "        9.83521581e-01, 7.93657899e-02, 4.28347290e-01, 2.04542860e-01,\n",
    "        4.50636476e-01, 5.47763586e-01],\n",
    "       [9.33267102e-02, 2.96860784e-01, 9.27584231e-01, 5.69003761e-01,\n",
    "        4.57412004e-01, 7.53525972e-01, 7.41862178e-01, 4.85790335e-02,\n",
    "        7.08697379e-01, 8.39243352e-01],\n",
    "       [1.65937886e-01, 7.80997932e-01, 2.86536604e-01, 3.06469738e-01,\n",
    "        6.65261447e-01, 1.11392170e-01, 6.64872468e-01, 8.87856781e-01,\n",
    "        6.96311295e-01, 4.40327883e-01],\n",
    "       [4.38214391e-01, 7.65096068e-01, 5.65641999e-01, 8.49041641e-02,\n",
    "        5.82671106e-01, 8.14843714e-01, 3.37066382e-01, 9.27576602e-01,\n",
    "        7.50716984e-01, 5.74063838e-01],\n",
    "       [7.51644015e-01, 7.91489631e-02, 8.59389067e-01, 8.21504116e-01,\n",
    "        9.09871638e-01, 1.28631204e-01, 8.17800835e-02, 1.38415575e-01,\n",
    "        3.99378717e-01, 4.24306870e-01],\n",
    "       [5.62218368e-01, 1.22243546e-01, 2.01399505e-01, 8.11644375e-01,\n",
    "        4.67987567e-01, 8.07938218e-01, 7.42637832e-03, 5.51592708e-01,\n",
    "        9.31932151e-01, 5.82175434e-01],\n",
    "       [2.06095725e-01, 7.17757583e-01, 3.78985852e-01, 6.68383956e-01,\n",
    "        2.93197222e-02, 6.35900378e-01, 3.21979336e-02, 7.44780660e-01,\n",
    "        4.72912997e-01, 1.21754356e-01],\n",
    "       [5.42635918e-01, 6.67744428e-02, 6.53364897e-01, 9.96086299e-01,\n",
    "        7.69397318e-01, 5.73774099e-01, 1.02635257e-01, 6.99834049e-01,\n",
    "        6.61167860e-01, 4.90971319e-02],\n",
    "       [7.92299330e-01, 5.18716574e-01, 4.25867707e-01, 7.88187146e-01,\n",
    "        4.11569238e-01, 4.81026262e-01, 1.81628838e-01, 3.21318895e-01,\n",
    "        8.45533013e-01, 1.86903745e-01],\n",
    "       [4.17291075e-01, 9.89034534e-01, 2.36599818e-01, 9.16832328e-01,\n",
    "        9.18397486e-01, 9.12963450e-02, 4.63652730e-01, 5.02216339e-01,\n",
    "        3.13668936e-01, 4.73395362e-02],\n",
    "       [2.41685644e-01, 9.55296382e-02, 2.38249913e-01, 8.07791114e-01,\n",
    "        8.94978285e-01, 4.32228930e-02, 3.01946849e-01, 9.80582178e-01,\n",
    "        5.39504826e-01, 6.26309335e-01],\n",
    "       [5.54540846e-03, 4.84909445e-01, 9.88328516e-01, 3.75185519e-01,\n",
    "        9.70381573e-02, 4.61908758e-01, 9.63004470e-01, 3.41830611e-01,\n",
    "        7.98922718e-01, 7.98846304e-01],\n",
    "       [2.08248302e-01, 4.43367690e-01, 7.15601265e-01, 4.10519779e-01,\n",
    "        1.91006958e-01, 9.67494309e-01, 6.50750339e-01, 8.65459859e-01,\n",
    "        2.52423584e-02, 2.66905814e-01],\n",
    "       [5.02071083e-01, 6.74486384e-02, 9.93033290e-01, 2.36462399e-01,\n",
    "        3.74292195e-01, 2.14011908e-01, 1.05445869e-01, 2.32479781e-01,\n",
    "        3.00610125e-01, 6.34442270e-01],\n",
    "       [2.81234771e-01, 3.62276763e-01, 5.94284385e-03, 3.65719140e-01,\n",
    "        5.33885956e-01, 1.62015840e-01, 5.97433090e-01, 2.93152481e-01,\n",
    "        6.32050514e-01, 2.61966046e-02],\n",
    "       [8.87593448e-01, 1.61186308e-02, 1.26958027e-01, 7.77162433e-01,\n",
    "        4.58952338e-02, 7.10998714e-01, 9.71046150e-01, 8.71682942e-01,\n",
    "        7.10161626e-01, 9.58509743e-01],\n",
    "       [4.29813325e-01, 8.72878909e-01, 3.55957657e-01, 9.29763675e-01,\n",
    "        1.48777649e-01, 9.40029025e-01, 8.32716227e-01, 8.46054852e-01,\n",
    "        1.23923011e-01, 5.96486926e-01],\n",
    "       [1.63924806e-02, 7.21184373e-01, 7.73751410e-03, 8.48222747e-02,\n",
    "        2.25498408e-01, 8.75124514e-01, 3.63576323e-01, 5.39959908e-01,\n",
    "        5.68103194e-01, 2.25463361e-01],\n",
    "       [5.72146773e-01, 6.60951793e-01, 2.98245400e-01, 4.18626845e-01,\n",
    "        4.53088939e-01, 9.32350636e-01, 5.87493777e-01, 9.48252380e-01,\n",
    "        5.56034744e-01, 5.00561416e-01],\n",
    "       [3.53221106e-03, 4.80889052e-01, 9.27455008e-01, 1.98365688e-01,\n",
    "        5.20911328e-02, 4.06778902e-01, 3.72396469e-01, 8.57153058e-01,\n",
    "        2.66111158e-02, 9.20149207e-01],\n",
    "       [6.80903018e-01, 9.04226005e-01, 6.07529044e-01, 8.11953306e-01,\n",
    "        3.35543871e-01, 3.49566221e-01, 3.89874220e-01, 7.54797101e-01,\n",
    "        3.69291186e-01, 2.42219806e-01],\n",
    "       [9.37668383e-01, 9.08011079e-01, 3.48797321e-01, 6.34638071e-01,\n",
    "        2.73842216e-01, 2.06115127e-01, 3.36339533e-01, 3.27099890e-01,\n",
    "        8.82276118e-01, 8.22303832e-01],\n",
    "       [7.09623218e-01, 9.59345222e-01, 4.22543347e-01, 2.45033041e-01,\n",
    "        1.17398441e-01, 3.01053345e-01, 1.45263731e-01, 9.21861008e-02,\n",
    "        6.02932215e-01, 3.64187449e-01],\n",
    "       [5.64570367e-01, 1.91335723e-01, 6.76905870e-01, 2.15505451e-01,\n",
    "        2.78023601e-01, 7.41760433e-01, 5.59737921e-01, 3.34836423e-01,\n",
    "        5.42988777e-01, 6.93984687e-01],\n",
    "       [9.12132144e-01, 5.80713212e-01, 2.32686386e-01, 7.46697605e-01,\n",
    "        7.77769029e-01, 2.00401321e-01, 8.20574224e-01, 4.64934856e-01,\n",
    "        7.79766679e-01, 2.37478226e-01],\n",
    "       [3.32580268e-01, 9.53697145e-01, 6.57815099e-01, 7.72877812e-01,\n",
    "        6.88374341e-01, 2.04304114e-01, 4.70688760e-01, 8.08963895e-01,\n",
    "        6.75035119e-01, 6.02788571e-03],\n",
    "       [8.74077454e-02, 3.46794724e-01, 9.44365561e-01, 4.91190493e-01,\n",
    "        2.70176262e-01, 3.60423714e-01, 2.10652635e-01, 4.21200067e-01,\n",
    "        2.18035445e-01, 8.45752478e-01],\n",
    "       [4.56270605e-01, 2.79802024e-01, 9.32891667e-01, 3.14351350e-01,\n",
    "        9.09714639e-01, 4.34180908e-02, 7.07115054e-01, 4.83889043e-01,\n",
    "        4.44221050e-01, 3.63233462e-02],\n",
    "       [4.06831913e-02, 3.32753628e-01, 9.47119534e-01, 6.17659986e-01,\n",
    "        3.68874848e-01, 6.11977041e-01, 2.06131533e-01, 1.65066436e-01,\n",
    "        3.61817271e-01, 8.63353372e-01],\n",
    "       [5.09401739e-01, 2.96901524e-01, 9.50251639e-01, 8.15966070e-01,\n",
    "        3.22973937e-01, 9.72098231e-01, 9.87351120e-01, 4.08660144e-01,\n",
    "        6.55923128e-01, 4.05653208e-01],\n",
    "       [2.57348120e-01, 8.26526731e-02, 2.63610333e-01, 2.71479845e-01,\n",
    "        3.98639083e-01, 1.84886038e-01, 9.53818381e-01, 1.02879882e-01,\n",
    "        6.25208557e-01, 4.41697389e-01],\n",
    "       [4.23518062e-01, 3.71991783e-01, 8.68314683e-01, 2.80476987e-01,\n",
    "        2.05761567e-02, 9.18097019e-01, 8.64480257e-01, 2.76901782e-01,\n",
    "        5.23487568e-01, 1.09088197e-01],\n",
    "       [9.34270695e-02, 8.37466121e-01, 4.10265714e-01, 6.61716521e-01,\n",
    "        9.43200588e-01, 2.45130599e-01, 1.31598311e-02, 2.41484065e-02,\n",
    "        7.09385693e-01, 9.24551904e-01],\n",
    "       [4.67330277e-01, 3.75109136e-01, 5.42860448e-01, 8.58916819e-01,\n",
    "        6.52153850e-01, 2.32979894e-01, 7.74580181e-01, 1.34613499e-01,\n",
    "        1.65559977e-01, 6.12682283e-01],\n",
    "       [2.38783404e-01, 7.04778552e-01, 3.49518538e-01, 2.77423948e-01,\n",
    "        9.98918414e-01, 4.06161249e-02, 6.45822525e-01, 3.86995859e-02,\n",
    "        7.60210276e-01, 2.30089962e-01],\n",
    "       [8.98318663e-02, 6.48449719e-01, 7.32601225e-01, 6.78095341e-01,\n",
    "        5.19009456e-02, 2.94306934e-01, 4.51088339e-01, 2.87103295e-01,\n",
    "        8.10513437e-01, 1.31115109e-01],\n",
    "       [6.12179339e-01, 9.88214970e-01, 9.02556539e-01, 2.22157061e-01,\n",
    "        8.18876142e-05, 9.80597317e-01, 8.82712960e-01, 9.19472456e-01,\n",
    "        4.15503561e-01, 7.44615436e-01],\n",
    "       [2.12831497e-01, 3.92304063e-01, 8.51548076e-01, 1.27612218e-01,\n",
    "        8.93865347e-01, 4.96507972e-01, 4.26095665e-01, 3.05646390e-01,\n",
    "        9.16848779e-01, 5.17623484e-01],\n",
    "       [8.04026365e-01, 8.57651770e-01, 9.22382355e-01, 3.03380728e-01,\n",
    "        3.39810848e-01, 5.95073879e-01, 4.41324145e-01, 9.32842553e-01,\n",
    "        3.97564054e-01, 4.77778047e-01],\n",
    "       [6.17186069e-01, 4.04739499e-01, 9.92478430e-01, 9.88512859e-02,\n",
    "        2.20603317e-01, 3.22655141e-01, 1.47722840e-01, 2.84219235e-01,\n",
    "        7.79245317e-01, 5.22891998e-01],\n",
    "       [3.39536369e-02, 9.82622564e-01, 6.16006494e-01, 5.89394793e-02,\n",
    "        6.61168754e-01, 3.78369361e-01, 1.35673299e-01, 5.63664615e-01,\n",
    "        7.27079928e-01, 6.71126604e-01],\n",
    "       [2.47513160e-01, 5.24866223e-01, 5.37663460e-01, 7.16803372e-01,\n",
    "        3.59867334e-01, 7.97732592e-01, 6.27921820e-01, 3.83316055e-02,\n",
    "        5.46479046e-01, 8.61912072e-01],\n",
    "       [5.67574143e-01, 1.75828263e-01, 5.10376394e-01, 7.56945848e-01,\n",
    "        1.10105194e-01, 8.17099094e-01, 1.67481646e-01, 5.34076512e-01,\n",
    "        3.85743469e-01, 2.48623773e-01],\n",
    "       [6.47432506e-01, 3.73921096e-02, 7.60045826e-01, 5.26940644e-01,\n",
    "        8.75771224e-01, 5.20718336e-01, 3.50331701e-02, 1.43600971e-01,\n",
    "        7.95604587e-01, 4.91976053e-01],\n",
    "       [4.41879272e-01, 3.18434775e-01, 2.84549206e-01, 9.65886295e-01,\n",
    "        4.32969332e-01, 8.84003043e-01, 6.48163140e-01, 8.58427644e-01,\n",
    "        8.52449536e-01, 9.56312001e-01],\n",
    "       [6.97942257e-01, 8.05396914e-01, 7.33127892e-01, 6.05226815e-01,\n",
    "        7.17354119e-01, 7.15750396e-01, 4.09077927e-02, 5.16110837e-01,\n",
    "        7.92651355e-01, 2.42962182e-01],\n",
    "       [4.65147972e-01, 4.34985697e-01, 4.02787179e-01, 1.21839531e-01,\n",
    "        5.25711536e-01, 4.46248353e-01, 6.63392782e-01, 5.49413085e-01,\n",
    "        2.75429301e-02, 3.19179893e-02],\n",
    "       [7.01359808e-01, 7.07581103e-01, 9.59939122e-01, 8.76704693e-01,\n",
    "        4.68059659e-01, 6.25906527e-01, 4.57181722e-01, 2.22946241e-01,\n",
    "        3.76677006e-01, 1.03884235e-01],\n",
    "       [6.66527092e-01, 1.92030147e-01, 4.75467801e-01, 9.67436612e-01,\n",
    "        3.16689312e-02, 1.51729956e-01, 2.98579186e-01, 9.41806972e-01,\n",
    "        9.08841789e-01, 1.62000835e-01],\n",
    "       [9.81117785e-01, 7.50747502e-01, 5.39977074e-01, 9.31702912e-01,\n",
    "        8.80607128e-01, 3.91316503e-01, 6.56343222e-01, 6.47385120e-01,\n",
    "        3.26968193e-01, 1.79390177e-01],\n",
    "       [4.66809869e-01, 2.63281047e-01, 3.55065137e-01, 9.54143941e-01,\n",
    "        4.61137861e-01, 6.84891462e-01, 3.36229891e-01, 9.95861053e-01,\n",
    "        6.58767581e-01, 1.96009472e-01],\n",
    "       [9.81839970e-02, 9.43180561e-01, 9.44777846e-01, 6.21328354e-01,\n",
    "        1.69914998e-02, 2.25534886e-01, 8.01276803e-01, 8.75459850e-01,\n",
    "        4.53989804e-01, 3.65520626e-01],\n",
    "       [2.74224997e-01, 1.16970517e-01, 1.15744539e-01, 9.52602684e-01,\n",
    "        8.08626115e-01, 1.64779365e-01, 2.07050055e-01, 6.55551553e-01,\n",
    "        7.64664233e-01, 8.10314834e-01],\n",
    "       [1.63337693e-01, 9.84128296e-01, 2.27802068e-01, 5.89415431e-01,\n",
    "        5.87615728e-01, 9.67361867e-01, 6.57667458e-01, 5.84904253e-01,\n",
    "        5.18772602e-01, 7.64657557e-01],\n",
    "       [1.06055260e-01, 2.09190114e-03, 9.52488840e-01, 4.98657674e-01,\n",
    "        3.28335375e-01, 3.68053257e-01, 8.03843319e-01, 3.82370204e-01,\n",
    "        7.70169199e-01, 4.40461993e-01],\n",
    "       [8.44077468e-01, 7.62040615e-02, 4.81128335e-01, 4.66849715e-01,\n",
    "        2.64327973e-01, 9.43614721e-01, 9.05028462e-01, 4.43596303e-01,\n",
    "        9.71596092e-02, 2.06783146e-01],\n",
    "       [2.71491826e-01, 4.84219760e-01, 3.38377118e-01, 7.74136066e-01,\n",
    "        4.76026595e-01, 8.70370507e-01, 9.95781779e-01, 2.19835952e-01,\n",
    "        6.11671388e-01, 8.47502291e-01],\n",
    "       [9.45236623e-01, 2.90086418e-01, 7.27042735e-01, 1.50161488e-02,\n",
    "        8.79142463e-01, 6.39385507e-02, 7.33395398e-01, 9.94610369e-01,\n",
    "        5.01189768e-01, 2.09333986e-01],\n",
    "       [5.94643593e-01, 6.24149978e-01, 6.68072760e-01, 1.72611743e-01,\n",
    "        8.98712695e-01, 6.20991349e-01, 4.35687043e-02, 6.84041083e-01,\n",
    "        1.96084052e-01, 2.73407809e-02],\n",
    "       [5.50953269e-01, 8.13313663e-01, 8.59941125e-01, 1.03520922e-01,\n",
    "        6.63042784e-01, 7.10075200e-01, 2.94516981e-01, 9.71364021e-01,\n",
    "        2.78687477e-01, 6.99821860e-02],\n",
    "       [5.19280374e-01, 6.94314897e-01, 2.44659781e-01, 3.38582188e-01,\n",
    "        5.63627958e-01, 8.86678159e-01, 7.47325897e-01, 2.09591955e-01,\n",
    "        2.51777083e-01, 5.23880661e-01],\n",
    "       [7.68958688e-01, 6.18761778e-01, 5.01324296e-01, 5.97125351e-01,\n",
    "        7.56060004e-01, 5.37079811e-01, 8.97752762e-01, 9.47067499e-01,\n",
    "        9.15354490e-01, 7.54518330e-01],\n",
    "       [2.46321008e-01, 3.85271460e-01, 2.79999942e-01, 6.57660246e-01,\n",
    "        3.24221611e-01, 7.54391611e-01, 1.13509081e-01, 7.75364757e-01,\n",
    "        5.85901976e-01, 8.35388660e-01],\n",
    "       [4.30875659e-01, 6.24964476e-01, 5.54412127e-01, 9.75671291e-01,\n",
    "        7.55474389e-01, 5.44813275e-01, 1.74032092e-01, 9.04114246e-01,\n",
    "        2.05837786e-01, 6.50043249e-01],\n",
    "       [9.36471879e-01, 2.23579630e-01, 2.25923538e-01, 8.51818919e-01,\n",
    "        8.27655017e-01, 3.51703346e-01, 2.65096277e-01, 1.27388477e-01,\n",
    "        9.87936080e-01, 8.35343122e-01],\n",
    "       [8.99391592e-01, 5.13679326e-01, 1.14384830e-01, 5.25803380e-02,\n",
    "        3.30582112e-01, 9.20330405e-01, 9.47581828e-01, 8.41163874e-01,\n",
    "        1.58679143e-01, 4.19923156e-01],\n",
    "       [2.46242926e-01, 2.05349773e-01, 6.84825838e-01, 4.86111671e-01,\n",
    "        3.24909657e-01, 1.00214459e-01, 5.44763386e-01, 3.47025156e-01,\n",
    "        3.91095817e-01, 3.10508728e-01],\n",
    "       [3.87195200e-01, 5.55859566e-01, 1.41438060e-02, 8.47647011e-01,\n",
    "        9.21919882e-01, 5.50529718e-01, 2.68021107e-01, 9.90239024e-01,\n",
    "        3.83194029e-01, 6.93655372e-01],\n",
    "       [6.89952552e-01, 4.34309065e-01, 1.99158162e-01, 9.66579378e-01,\n",
    "        6.36908561e-02, 4.85149384e-01, 2.20730707e-01, 2.93974131e-01,\n",
    "        8.28527331e-01, 3.67265552e-01],\n",
    "       [8.33482668e-02, 1.96309000e-01, 8.60373437e-01, 9.77028847e-01,\n",
    "        2.67982155e-01, 6.75408959e-01, 8.11989978e-02, 7.23465621e-01,\n",
    "        4.16436613e-01, 9.18159902e-01],\n",
    "       [3.11536163e-01, 9.41466987e-01, 5.03247440e-01, 3.48892927e-01,\n",
    "        6.47019625e-01, 2.49746203e-01, 2.29763597e-01, 1.96346447e-01,\n",
    "        9.59899545e-01, 4.92913723e-01],\n",
    "       [7.51614988e-01, 4.73991871e-01, 5.87540150e-01, 5.84138989e-01,\n",
    "        9.79886293e-01, 6.68433130e-01, 2.39769474e-01, 1.51976589e-02,\n",
    "        2.18682140e-01, 4.55519646e-01],\n",
    "       [3.93420339e-01, 8.12326252e-01, 7.85556734e-01, 8.90959650e-02,\n",
    "        9.52010751e-01, 5.27456701e-01, 5.96403956e-01, 4.05056775e-01,\n",
    "        6.49500966e-01, 8.71326327e-01],\n",
    "       [6.73935950e-01, 9.70098555e-01, 7.01122224e-01, 8.21720719e-01,\n",
    "        4.50395830e-02, 6.72698498e-01, 6.54752672e-01, 1.01746053e-01,\n",
    "        8.42387497e-01, 6.14172399e-01],\n",
    "       [9.83280912e-02, 5.94467103e-01, 4.78415847e-01, 2.33293563e-01,\n",
    "        1.97560899e-02, 3.65567267e-01, 6.19851053e-01, 3.29279125e-01,\n",
    "        3.07254642e-01, 7.51121223e-01],\n",
    "       [7.58624673e-01, 7.18765855e-01, 1.01181954e-01, 5.16165972e-01,\n",
    "        5.57798684e-01, 7.44804502e-01, 9.03177738e-01, 3.69038880e-01,\n",
    "        4.28663462e-01, 7.32767463e-01],\n",
    "       [6.62636399e-01, 5.57869911e-01, 3.50139618e-01, 1.95352346e-01,\n",
    "        1.83807373e-01, 8.15832913e-02, 8.12008530e-02, 8.45798194e-01,\n",
    "        3.83672744e-01, 6.07396215e-02],\n",
    "       [8.96425664e-01, 2.23270476e-01, 2.68124431e-01, 1.94497839e-01,\n",
    "        9.67501044e-01, 1.12540089e-01, 7.22163260e-01, 9.32088733e-01,\n",
    "        6.68001294e-01, 8.58726621e-01],\n",
    "       [2.42447108e-01, 6.73927963e-01, 7.00871348e-01, 4.58332509e-01,\n",
    "        8.70545626e-01, 6.94386125e-01, 8.94877791e-01, 7.53204346e-01,\n",
    "        5.20290434e-01, 4.98688221e-01],\n",
    "       [4.53727633e-01, 2.16468628e-02, 5.35141408e-01, 4.22973245e-01,\n",
    "        1.57533601e-01, 1.19069695e-01, 4.49351877e-01, 3.99130546e-02,\n",
    "        9.86579895e-01, 3.78120929e-01],\n",
    "       [3.82109195e-01, 5.11263013e-02, 4.26672339e-01, 1.57454368e-02,\n",
    "        3.00936326e-02, 3.39099228e-01, 8.20968926e-01, 4.58821088e-01,\n",
    "        1.48405796e-02, 1.63220033e-01],\n",
    "       [7.39922702e-01, 7.38293707e-01, 7.54522920e-01, 3.51669371e-01,\n",
    "        3.52276951e-01, 8.02075684e-01, 3.98137897e-01, 7.27191031e-01,\n",
    "        5.81122994e-01, 3.64341676e-01],\n",
    "       [8.00065175e-02, 1.16125375e-01, 8.89558733e-01, 4.52340513e-01,\n",
    "        9.94004548e-01, 3.63896936e-01, 2.49954298e-01, 3.50539327e-01,\n",
    "        3.43086094e-01, 6.37356758e-01],\n",
    "       [1.27375638e-02, 7.63268650e-01, 4.16414618e-01, 4.32239205e-01,\n",
    "        4.81115013e-01, 4.49212462e-01, 4.97470886e-01, 3.45904320e-01,\n",
    "        4.53346133e-01, 4.04651344e-01],\n",
    "       [5.18242717e-01, 6.23269081e-01, 2.41040602e-01, 5.08437157e-01,\n",
    "        5.94621897e-01, 1.69483144e-02, 5.20493746e-01, 2.39293247e-01,\n",
    "        4.04538542e-01, 8.26530159e-01],\n",
    "       [3.26235592e-01, 4.83216912e-01, 2.47411542e-02, 3.08750868e-01,\n",
    "        6.39721096e-01, 3.15161765e-01, 2.05797508e-01, 2.90655673e-01,\n",
    "        9.54378307e-01, 8.68018195e-02],\n",
    "       [4.63357776e-01, 5.83869033e-02, 5.38658261e-01, 1.46035731e-01,\n",
    "        6.34084821e-01, 2.64397472e-01, 6.90915406e-01, 3.47146064e-01,\n",
    "        4.16848855e-03, 2.94894695e-01]],dtype=np.float32)\n",
    "\n",
    "# Define the first dense layer\n",
    "dense1 = tf.keras.layers.Dense(7, activation='sigmoid')(borrower_features)\n",
    "\n",
    "# Define a dense layer with 3 output nodes\n",
    "dense2 = tf.keras.layers.Dense(3,activation=\"sigmoid\")(dense1)\n",
    "\n",
    "# Define a dense layer with 1 output node\n",
    "predictions = tf.keras.layers.Dense(1,activation=\"sigmoid\")(dense2)\n",
    "\n",
    "# Print the shapes of dense1, dense2, and predictions\n",
    "print('\\n shape of dense1: ', dense1.shape)\n",
    "print('\\n shape of dense2: ', dense2.shape)\n",
    "print('\\n shape of predictions: ', predictions.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Activation Functions\n",
    "\n",
    "A typical hidden layer consists of 2 operations:       \n",
    "1) Linear: performs matrix multiplication, which is a linear operation.         \n",
    "2) Nonlinear: activation function.         \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8\n",
      "0.8\n"
     ]
    }
   ],
   "source": [
    "# a simple example where we assume that the weight on age is 1 and the weight on the bill amount is 2\n",
    "\n",
    "# Define example borrower features\n",
    "young, old = 0.3, 0.6\n",
    "low_bill, high_bill = 0.1, 0.5\n",
    "\n",
    "# apply matrix multiplication step for all feature combination\n",
    "young_high = 1.0*young + 2.0*high_bill\n",
    "young_low = 1.0*young + 2.0*low_bill\n",
    "old_high = 1.0*old + 2.0*high_bill\n",
    "old_low = 1.0*old + 2.0*low_bill\n",
    "\n",
    "# Difference in default predictions for young\n",
    "print(young_high - young_low)\n",
    "\n",
    "# Difference in default predictions for old\n",
    "print(old_high - old_low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16337568\n",
      "0.14204389\n"
     ]
    }
   ],
   "source": [
    "# with activation function\n",
    "print(tf.keras.activations.sigmoid(young_high).numpy()-tf.keras.activations.sigmoid(young_low).numpy())\n",
    "\n",
    "print(tf.keras.activations.sigmoid(old_high).numpy()-tf.keras.activations.sigmoid(old_low).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most common activation function: sigmoid, ReLu and softmax.        \n",
    "\n",
    "The sigmoid activation function is used primarily in the output layer of binary classificaiton problem.     \n",
    "Low-level: tf.keras.activations.sigmoid()         \n",
    "High-level: sigmoid       \n",
    "\n",
    "The ReLu activation function (Rectified Linear Unit) is used in all layers other htan the output layer. This activation simply takes the maximum of the value passed to it and 0 if x is negative.          \n",
    "Low-level: tf.keras.activations.relu()         \n",
    "High-level: relu         \n",
    "\n",
    "The softmax activation function is used in the output layer in classification problems with more than two classes. The outputs from a softmax activation function can be interpreted as predicted class probabilities in multiclass classification problems.      \n",
    "Low-level: tf.keras.activations.softmax()       \n",
    "High-level: softmax          \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input layer\n",
    "inputs = tf.constant(borrower_features, dtype = tf.float32)\n",
    "\n",
    "# Define dense layer 1\n",
    "dense1 = tf.keras.layers.Dense(16, activation=\"relu\")(inputs)\n",
    "\n",
    "# Define dense 2\n",
    "dense2 = tf.keras.layers.Dense(8, activation=\"sigmoid\")(dense1)\n",
    "\n",
    "# Define output layer\n",
    "outputs = tf.keras.layers.Dense(4, activation=\"softmax\")(dense2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.1105312  0.19927394 0.20831117 0.48188367]\n",
      " [0.11558039 0.19875197 0.20812516 0.47754243]\n",
      " [0.11165091 0.19399762 0.20439456 0.48995692]\n",
      " [0.11063999 0.19841023 0.20914055 0.48180923]\n",
      " [0.11378781 0.20506497 0.20466019 0.476487  ]\n",
      " [0.11229768 0.19330044 0.20363392 0.490768  ]\n",
      " [0.11060317 0.19343947 0.19988917 0.4960683 ]\n",
      " [0.10830142 0.1926553  0.20854698 0.49049637]\n",
      " [0.11424928 0.19637963 0.20755497 0.48181608]\n",
      " [0.1126796  0.2006236  0.21552572 0.47117105]\n",
      " [0.11160199 0.19368425 0.20495002 0.48976383]\n",
      " [0.1067858  0.20228057 0.21580915 0.47512448]\n",
      " [0.11331404 0.20366342 0.2087831  0.47423944]\n",
      " [0.10725141 0.20448974 0.21608381 0.472175  ]\n",
      " [0.10671645 0.18948689 0.20531829 0.4984784 ]\n",
      " [0.11295969 0.19189045 0.20054823 0.49460164]\n",
      " [0.1190635  0.18990554 0.19749677 0.4935342 ]\n",
      " [0.10769681 0.20565833 0.21392554 0.4727194 ]\n",
      " [0.11045446 0.20933622 0.21675651 0.46345285]\n",
      " [0.11290117 0.20186439 0.21643701 0.46879745]\n",
      " [0.10897365 0.20334868 0.21717392 0.47050372]\n",
      " [0.10657024 0.20340462 0.22399177 0.46603337]\n",
      " [0.11524394 0.20025355 0.2065982  0.47790435]\n",
      " [0.10927545 0.21213399 0.21688128 0.46170932]\n",
      " [0.11036664 0.18265198 0.19542211 0.51155925]\n",
      " [0.11379617 0.18718433 0.1969357  0.5020838 ]\n",
      " [0.11102641 0.19889647 0.20473786 0.48533928]\n",
      " [0.10907462 0.20482072 0.21764213 0.4684625 ]\n",
      " [0.10831576 0.20038567 0.22721376 0.46408483]\n",
      " [0.11026818 0.192733   0.20525138 0.4917474 ]\n",
      " [0.11449803 0.20094211 0.21493039 0.4696296 ]\n",
      " [0.11410032 0.19326259 0.20474693 0.48789018]\n",
      " [0.10985476 0.18866464 0.19837326 0.5031073 ]\n",
      " [0.11321136 0.19442973 0.20186357 0.49049532]\n",
      " [0.10953765 0.20119268 0.2164613  0.47280833]\n",
      " [0.11163966 0.19831316 0.2109841  0.479063  ]\n",
      " [0.10939402 0.19457044 0.20663916 0.48939648]\n",
      " [0.11102261 0.20010066 0.21177487 0.4771018 ]\n",
      " [0.11586583 0.1896351  0.19719    0.49730906]\n",
      " [0.11004435 0.19538265 0.20613818 0.48843482]\n",
      " [0.11259286 0.18762057 0.19084111 0.5089454 ]\n",
      " [0.11080331 0.19615345 0.20705757 0.4859857 ]\n",
      " [0.10542542 0.18458682 0.20642832 0.50355947]\n",
      " [0.10871534 0.20448345 0.21502471 0.47177652]\n",
      " [0.10828221 0.18311366 0.1997028  0.5089013 ]\n",
      " [0.11406558 0.21351369 0.21469232 0.4577284 ]\n",
      " [0.105976   0.19563681 0.21249871 0.48588848]\n",
      " [0.11383094 0.1979527  0.20221707 0.4859993 ]\n",
      " [0.10928926 0.19298689 0.2078866  0.48983726]\n",
      " [0.11492088 0.17568146 0.18353607 0.52586156]\n",
      " [0.1161517  0.19173415 0.1967452  0.49536893]\n",
      " [0.11762445 0.18322083 0.18776965 0.51138514]\n",
      " [0.11301608 0.19140367 0.20136528 0.494215  ]\n",
      " [0.11650822 0.18881771 0.20256431 0.4921098 ]\n",
      " [0.10622111 0.1943939  0.21274565 0.48663938]\n",
      " [0.10721812 0.19858183 0.21792074 0.4762793 ]\n",
      " [0.11129986 0.20624419 0.2088363  0.4736197 ]\n",
      " [0.10846916 0.19926871 0.21417977 0.4780823 ]\n",
      " [0.11543045 0.19499671 0.20785823 0.48171467]\n",
      " [0.11472616 0.19566199 0.19812228 0.49148956]\n",
      " [0.10790893 0.1885262  0.20515496 0.49840993]\n",
      " [0.10811504 0.20040007 0.22345433 0.4680306 ]\n",
      " [0.11208559 0.19506228 0.2009676  0.49188456]\n",
      " [0.10864721 0.201836   0.2184765  0.4710403 ]\n",
      " [0.11228041 0.18114877 0.18674518 0.51982564]\n",
      " [0.10840522 0.21742798 0.21969797 0.45446882]\n",
      " [0.113337   0.19448227 0.2092291  0.48295164]\n",
      " [0.10850785 0.19025658 0.20659482 0.4946407 ]\n",
      " [0.10640541 0.19106723 0.21037553 0.49215183]\n",
      " [0.10540175 0.19286698 0.21223152 0.48949975]\n",
      " [0.11908932 0.18990175 0.1854024  0.5056066 ]\n",
      " [0.11971039 0.19240747 0.20098929 0.48689282]\n",
      " [0.12208233 0.18203628 0.18810953 0.5077719 ]\n",
      " [0.10977089 0.19375172 0.20939168 0.48708567]\n",
      " [0.11202823 0.18902011 0.1989301  0.5000216 ]\n",
      " [0.11045123 0.20636275 0.2167147  0.4664713 ]\n",
      " [0.11373455 0.20032102 0.21054652 0.47539794]\n",
      " [0.10801653 0.21278831 0.21933575 0.4598594 ]\n",
      " [0.11624637 0.19668715 0.19559799 0.49146852]\n",
      " [0.1088906  0.19705929 0.20959784 0.48445234]\n",
      " [0.11406914 0.21041502 0.21529675 0.46021912]\n",
      " [0.10435356 0.20500602 0.23159039 0.45905006]\n",
      " [0.1099856  0.19881228 0.2106762  0.4805259 ]\n",
      " [0.11512661 0.19714265 0.2071206  0.48061016]\n",
      " [0.11138599 0.19953285 0.20854157 0.48053956]\n",
      " [0.11819808 0.18642756 0.19086355 0.5045109 ]\n",
      " [0.10608768 0.18929143 0.21234746 0.49227348]\n",
      " [0.10699471 0.19441234 0.20729628 0.49129668]\n",
      " [0.10927485 0.1982943  0.20905967 0.48337123]\n",
      " [0.11600116 0.2023512  0.20420906 0.47743863]\n",
      " [0.11689461 0.20394148 0.19781536 0.48134857]\n",
      " [0.11547948 0.18472226 0.19126777 0.5085305 ]\n",
      " [0.10677099 0.20266506 0.22550987 0.46505412]\n",
      " [0.11113179 0.19713047 0.20829353 0.4834442 ]\n",
      " [0.1149728  0.18742852 0.19766584 0.49993283]\n",
      " [0.1142473  0.20069808 0.20239753 0.48265702]\n",
      " [0.11345199 0.19635254 0.2065166  0.48367894]\n",
      " [0.11051384 0.20787218 0.21143715 0.47017688]\n",
      " [0.11148044 0.2087094  0.21996862 0.45984155]\n",
      " [0.10961106 0.19684777 0.20342347 0.49011767]], shape=(100, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, you will again make use of credit card data. The target variable, default, indicates whether a credit card holder defaults on her payment in the following period. Since there are only two options--default or not--this is a binary classification problem. While the dataset has many features, you will focus on just three: the size of the three latest credit card bills. Finally, you will compute predictions from your untrained network, outputs, and compare those the target variable, default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default.payment.next.month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>689.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3272.0</td>\n",
       "      <td>3455.0</td>\n",
       "      <td>3261.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>14331.0</td>\n",
       "      <td>14948.0</td>\n",
       "      <td>15549.0</td>\n",
       "      <td>1518.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>28314.0</td>\n",
       "      <td>28959.0</td>\n",
       "      <td>29547.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>1069.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20940.0</td>\n",
       "      <td>19146.0</td>\n",
       "      <td>19131.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>36681.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>9000.0</td>\n",
       "      <td>689.0</td>\n",
       "      <td>679.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  PAY_4  \\\n",
       "0   1    20000.0    2          2         1   24      2      2     -1     -1   \n",
       "1   2   120000.0    2          2         2   26     -1      2      0      0   \n",
       "2   3    90000.0    2          2         2   34      0      0      0      0   \n",
       "3   4    50000.0    2          2         1   37      0      0      0      0   \n",
       "4   5    50000.0    1          2         1   57     -1      0     -1      0   \n",
       "\n",
       "   ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  \\\n",
       "0  ...        0.0        0.0        0.0       0.0     689.0       0.0   \n",
       "1  ...     3272.0     3455.0     3261.0       0.0    1000.0    1000.0   \n",
       "2  ...    14331.0    14948.0    15549.0    1518.0    1500.0    1000.0   \n",
       "3  ...    28314.0    28959.0    29547.0    2000.0    2019.0    1200.0   \n",
       "4  ...    20940.0    19146.0    19131.0    2000.0   36681.0   10000.0   \n",
       "\n",
       "   PAY_AMT4  PAY_AMT5  PAY_AMT6  default.payment.next.month  \n",
       "0       0.0       0.0       0.0                           1  \n",
       "1    1000.0       0.0    2000.0                           1  \n",
       "2    1000.0    1000.0    5000.0                           0  \n",
       "3    1100.0    1069.0    1000.0                           0  \n",
       "4    9000.0     689.0     679.0                           0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc_df = pd.read_csv(\"../Machine_Learning_basics/data/uci_credit_card.csv\")\n",
    "cc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "bill_amounts = np.array(cc_df[[\"BILL_AMT1\",\"BILL_AMT2\",\"BILL_AMT3\"]],np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "default = np.array(cc_df[[\"default.payment.next.month\"]],np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.        ]\n",
      " [ 0.18238378]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Construct input layer from features\n",
    "inputs = tf.constant(bill_amounts)\n",
    "\n",
    "# Define first dense layer\n",
    "dense1 = tf.keras.layers.Dense(3, activation='relu')(inputs)\n",
    "\n",
    "# Define second dense layer\n",
    "dense2 = tf.keras.layers.Dense(2,activation=\"relu\")(dense1)\n",
    "\n",
    "# Define output layer\n",
    "outputs = tf.keras.layers.Dense(1,activation=\"sigmoid\")(dense2)\n",
    "\n",
    "# Print error for first five examples\n",
    "error = default[:5] - outputs.numpy()[:5]\n",
    "print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiclass classification problems       \n",
    "In this exercise, we expand beyond binary classification to cover multiclass problems. A multiclass problem has targets that can take on three or more values. In the credit card dataset, the education variable can take on 6 different values, each corresponding to a different level of education. We will use that as our target in this exercise and will also expand the feature set from 3 to 10 columns.              \n",
    "\n",
    "As in the previous problem, you will define an input layer, dense layers, and an output layer. You will also print the untrained model's predictions, which are probabilities assigned to the classes. The tensor of features has been loaded and is available as borrower_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "borrower_features = np.array(cc_df[[\"BILL_AMT1\",\"BILL_AMT2\",\"BILL_AMT3\",\"BILL_AMT4\",\"BILL_AMT5\",\"BILL_AMT6\",\"PAY_AMT1\",\"PAY_AMT2\",\"PAY_AMT3\",\"PAY_AMT4\",\"PAY_AMT5\"]],np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.16175532 0.21448301 0.1641436  0.15772898 0.13908899 0.16280012]\n",
      " [0.17216966 0.17142151 0.15821598 0.17170802 0.1622757  0.16420914]\n",
      " [0.18177326 0.1902991  0.15739845 0.1547137  0.14012657 0.17568892]\n",
      " [0.20669936 0.20017597 0.11092839 0.20265287 0.1336803  0.14586306]\n",
      " [0.17216966 0.17142151 0.15821598 0.17170802 0.1622757  0.16420914]]\n"
     ]
    }
   ],
   "source": [
    "# Construct input layer from borrower features\n",
    "inputs = tf.constant(borrower_features)\n",
    "\n",
    "# Define first dense layer\n",
    "dense1 = tf.keras.layers.Dense(10, activation='sigmoid')(inputs)\n",
    "\n",
    "# Define second dense layer\n",
    "dense2 = tf.keras.layers.Dense(8,activation=\"relu\")(dense1)\n",
    "\n",
    "# Define output layer\n",
    "outputs = tf.keras.layers.Dense(6,activation=\"softmax\")(dense2)\n",
    "\n",
    "# Print first five predictions\n",
    "print(outputs.numpy()[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Optimisers\n",
    "\n",
    "In a nerual network, we pick a point, measure the loss, and then try to move to a lower loss.        \n",
    "\n",
    "Stochastic gradient descent (SGD) optimiser       \n",
    "tf.keras.optimizers.SGD()         \n",
    "learning_rate (0.5, 0.001)       \n",
    "\n",
    "RMS propagation optimiser        \n",
    "Applies different learning rates to each feature, useful for high dimensional porblem.        \n",
    "tf.keras.optimisers.RMSprop()            \n",
    "learning_rate       \n",
    "momentum (which allows the optimizer to break through local minima.)         \n",
    "decay (low value = prevent momenum from accumulating over long period during training)       \n",
    "\n",
    "Adam (adaptive moment) optimiser        \n",
    "tf.keras.optimisers.adam()           \n",
    "learning_rate       \n",
    "beta1 (similar to decay function, low beta->decay faster)       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model function\n",
    "def model(bias, weights, features=borrower_features):\n",
    "    product = tf.matmul(features,weights)\n",
    "    return tf.keras.activations.sigmoid(product+bias)\n",
    "\n",
    "def loss_function(bias, weights, targets=default, features = borrower_features):\n",
    "    predictions = model(bias, weights)\n",
    "    return tf.keras.losses.binary_crossentropy(targets, predictions) # for binary classificaiton prob, loss func\n",
    "\n",
    "#minimise the loss function with RMS propagation\n",
    "opt = tf.keras.optimizers.RMSprop(learning_rate=0.01,momentum=0.9)\n",
    "opt.minimize(lambda: loss_function(bias,weights),var_list=[bias,weights])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Training a network in TensorFlow\n",
    "\n",
    "We often need to initialise hundreds or thousands of variables. (mainly for the weights)    \n",
    "We use random or algorithmic generation of initial values for gradient descent.       \n",
    "\n",
    "We can draw them from a probability distribution, suc as the normal or uniform distribution. There are also specialised options, such as the Glorot initialiser, which are designed for ML algorithm.        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# low level approach to initialise a 500x500 variable\n",
    "\n",
    "# Define 500x500 random nomral variable\n",
    "weights = tf.Variable(tf.random.normal([500,500]))\n",
    "\n",
    "# Define 500x500 truncated random normal variable\n",
    "# discards very large and very small draws\n",
    "weights = tf.Variable(tf.random.truncated_normal([500,500]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# high level approach by initialising a dense layer using the defaulkeras options, \n",
    "# currently the Glorot uniform initialiser.\n",
    "\n",
    "# Define a dense layer with the default initialiser\n",
    "dense = tf.keras.layers.Dense(32,activation=\"relu\")\n",
    "\n",
    "# Define a dense layer with the zeros initialiser\n",
    "dense = tf.keras.layers.Dense(32,activation=\"relu\",kernel_initialiser=\"zeros\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For neual network, a solution for overfitting problem is to use dropout, an operation that will randomly drop the weights connected to certain nodes in a layer during the training process. This will force the network to develop more robust rules for classification, since it cannot rely on any particular nodes being passed to an activation function. This will tend to improve out-of-sample performance.      \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropout working\n",
    "\n",
    "# Define input data\n",
    "inputs = np.array(borrower_features, np.float32)\n",
    "\n",
    "# Define dense layer 1\n",
    "dense1 = tf.keras.layers.Dense(32,activation=\"relu\")(inputs)\n",
    "\n",
    "# define dense layer 2\n",
    "dense2 = tf.keras.layers.Dense(16, activation=\"relu\")(dense1)\n",
    "\n",
    "# apply dropout operation (apply a droupout layer)\n",
    "# dropout 25% of the nodes randomly\n",
    "dropout1 = tf.keras.layers.Dropout(0.25)(dense2)\n",
    "\n",
    "# Define output layer\n",
    "outputs = tf.layers.Dense(1, activation=\"sigmoid\")(dropout1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
