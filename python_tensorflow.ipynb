{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Library: TensorFlow 2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run this from tf env, with tensorflow 2.0+**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Introduction\n",
    "\n",
    "Tensorflow is an open-source library for graph-based numerical computation.     \n",
    "Has both low and high level APIs.       \n",
    "Can be used to perform addition, multiplication and differentiation.      \n",
    "Can be used to train ML models.       \n",
    "\n",
    "Important changes in TensorFlow 2.0:        \n",
    "Eager exucution is now enabled y default, which allows users to write simpler and more intuitive code.       \n",
    "Modeling building is now centered around the Keras and Estimators high-level APIs.         \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=5, shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0D Tensor\n",
    "d0 = tf.ones((1,))\n",
    "d0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=8, shape=(2,), dtype=float32, numpy=array([1., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1D Tensor\n",
    "d1 = tf.ones((2,))\n",
    "d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=11, shape=(2, 2), dtype=float32, numpy=\n",
       "array([[1., 1.],\n",
       "       [1., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2D Tensor\n",
    "d2 = tf.ones((2,2))\n",
    "d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=14, shape=(2, 2, 2), dtype=float32, numpy=\n",
       "array([[[1., 1.],\n",
       "        [1., 1.]],\n",
       "\n",
       "       [[1., 1.],\n",
       "        [1., 1.]]], dtype=float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3D Tensor\n",
    "d3 = tf.ones((2,2,2))\n",
    "d3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[1. 1.]\n",
      "  [1. 1.]]]\n"
     ]
    }
   ],
   "source": [
    "# Print the 3D tensor\n",
    "print(d3.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1 Defining constants in TensorFlow\n",
    "\n",
    "A constant is the simplest category of tensor.      \n",
    "A constant does not change and cannot be trained.      \n",
    "\n",
    "It can, however, have any dimension.      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import constant\n",
    "\n",
    "# Define a 2x3 constant tensor of 3s.\n",
    "a = constant(3, shape=[2,3])\n",
    "\n",
    "# define a 2x2 tensor, which is constructed from the 1D tensor: 1,2,3,4\n",
    "b = constant([1,2,3,4],shape=[2,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 3 3]\n",
      " [3 3 3]]\n",
      "[[1 2]\n",
      " [3 4]]\n"
     ]
    }
   ],
   "source": [
    "print(a.numpy())\n",
    "print(b.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3]\n",
      "[[0. 0.]\n",
      " [0. 0.]]\n",
      "[[0 0]\n",
      " [0 0]]\n",
      "[[1. 1.]\n",
      " [1. 1.]]\n",
      "[[1 1]\n",
      " [1 1]]\n",
      "[[7 7 7]\n",
      " [7 7 7]\n",
      " [7 7 7]]\n"
     ]
    }
   ],
   "source": [
    "# some convenient way of defining constant\n",
    "input_tensor = constant([1,2,3,4],shape=[2,2])\n",
    "\n",
    "a = tf.constant([1,2,3])\n",
    "\n",
    "b = tf.zeros([2,2])\n",
    "\n",
    "c = tf.zeros_like(input_tensor)\n",
    "\n",
    "d = tf.ones([2,2])\n",
    "\n",
    "e = tf. ones_like(input_tensor)\n",
    "\n",
    "f = tf.fill([3,3],7)\n",
    "\n",
    "print(a.numpy())\n",
    "print(b.numpy())\n",
    "print(c.numpy())\n",
    "print(d.numpy())\n",
    "print(e.numpy())\n",
    "print(f.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2 Defining and initialising variables\n",
    "\n",
    "Unlike a constant, a variable's value can change during computation. The value of a variable is shared, persistent and modifiable.         \n",
    "Its data type and shape are fixed.         \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a variable\n",
    "a0 = tf.Variable([1,2,3,4,5,6], dtype=tf.float32)\n",
    "a1 = tf.Variable([1,2,3,4,5,6], dtype=tf.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a constant\n",
    "b = tf.constant(2,tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute their product\n",
    "c0 = tf.multiply(a0,b)\n",
    "c1 = a0*b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.  4.  6.  8. 10. 12.]\n",
      "[ 2.  4.  6.  8. 10. 12.]\n"
     ]
    }
   ],
   "source": [
    "print(c0.numpy())\n",
    "print(c1.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining data as constants:        \n",
    "\n",
    "After you have imported constant, you will use it to transform a numpy array, credit_numpy, into a tensorflow constant, credit_constant. This array contains feature columns from a dataset on credit card holders and is previewed in the image below. We will return to this dataset in later chapters.             \n",
    "\n",
    "Note that tensorflow version 2.0 allows you to use data as either a numpy array or a tensorflow constant object. Using a constant will ensure that any operations performed with that object are done in tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_numpy = np.array([[ 2.0000e+00,  2.4000e+01,  1.0000e+00,  3.9130e+03],\n",
    "       [ 2.0000e+00,  2.6000e+01,  2.0000e+00,  2.6820e+03],\n",
    "       [ 2.0000e+00,  3.4000e+01,  2.0000e+00,  2.9239e+04],\n",
    "       [ 2.0000e+00,  3.7000e+01,  2.0000e+00,  3.5650e+03],\n",
    "       [ 3.0000e+00,  4.1000e+01,  1.0000e+00, -1.6450e+03],\n",
    "       [ 2.0000e+00,  4.6000e+01,  1.0000e+00,  4.7929e+04]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The datatype is: <dtype: 'float64'>\n",
      "The shape is: (6, 4)\n"
     ]
    }
   ],
   "source": [
    "# Import constant from TensorFlow\n",
    "from tensorflow import constant\n",
    "\n",
    "# Convert the credit_numpy array into a tensorflow constant\n",
    "credit_constant = constant(credit_numpy)\n",
    "\n",
    "# Print constant datatype\n",
    "print('The datatype is:', credit_constant.dtype)\n",
    "\n",
    "# Print constant shape\n",
    "print('The shape is:', credit_constant.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Operation of Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow has a model of computation that revolves around the use of graphs. A Tensorflow graph contains edges and nodes, where the edges are tensors and the modes are operations.      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The add() operation performs element-wise **addition** with two tensors.       \n",
    "Element-wise addition requires both tensors to have the same shape.            \n",
    "The add() operator is overloaded, which means that we can also perform addition using the plus symbol.      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3]\n",
      "[4 6]\n",
      "[[ 6  8]\n",
      " [10 12]]\n"
     ]
    }
   ],
   "source": [
    "# addition operator\n",
    "from tensorflow import constant, add\n",
    "\n",
    "# Define 0-dimensional tensors\n",
    "A0 = constant([1])\n",
    "B0 = constant([2])\n",
    "\n",
    "# Define 1-dimensional tensors\n",
    "A1 = constant([1,2])\n",
    "B1 = constant([3,4])\n",
    "\n",
    "# Define 2-dimensional tensors\n",
    "A2 = constant([[1,2],[3,4]])\n",
    "B2 = constant([[5,6],[7,8]])\n",
    "\n",
    "# Perform tensor addition with add()\n",
    "C0 = add(A0,B0) #scaler addition\n",
    "C1 = add(A1,B1) #vector addition\n",
    "C2 = add(A2,B2) #matrix addition\n",
    "\n",
    "print(C0.numpy())\n",
    "print(C1.numpy())\n",
    "print(C2.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Element-wise multiplication** performed using multiply() operation.        \n",
    "The tensors involved must have the same shape.     \n",
    "**Matrix multiplication** performed wutg matmul() operator.         \n",
    "The matmul(A,B) operation multiplies A by B.       \n",
    "Number of columns of A must equal to the number of rows of B.      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.]\n",
      "[[1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "[[1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import ones, matmul, multiply\n",
    "\n",
    "# Define tensors\n",
    "A0 = ones(1)\n",
    "A31 = ones([3,1])\n",
    "A34 = ones([3,4])\n",
    "A43 = ones([4,3])\n",
    "\n",
    "ex1 = multiply(A0,A0)\n",
    "ex2 = multiply(A31,A31)\n",
    "ex3 = multiply(A34,A34)\n",
    "\n",
    "print(ex1.numpy())\n",
    "print(ex2.numpy())\n",
    "print(ex3.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summing over tensor dimensions:          \n",
    "\n",
    "The reduce_sum() operator sums over the dimensions of a tensor.      \n",
    "reduce_sum(A) sums over all dimensions of A.      \n",
    "reduce_sum(A,i) sums over dimension i.       \n",
    "In each case we reduce the size of the tensor by summing over one of its dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]]]\n",
      "24.0\n",
      "[[2. 2. 2. 2.]\n",
      " [2. 2. 2. 2.]\n",
      " [2. 2. 2. 2.]]\n",
      "[[3. 3. 3. 3.]\n",
      " [3. 3. 3. 3.]]\n",
      "[[4. 4. 4.]\n",
      " [4. 4. 4.]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import ones, reduce_sum\n",
    "\n",
    "# Define a 2x3x4 tensors of ones\n",
    "A = ones([2,3,4])\n",
    "\n",
    "# Sum over all dimension\n",
    "B = reduce_sum(A)\n",
    "\n",
    "# Sum over dimension 0,1,2\n",
    "B0 = reduce_sum(A,0) # 3x4 matrix of 2s\n",
    "B1 = reduce_sum(A,1) # 2x4 matrix of 3s\n",
    "B2 = reduce_sum(A,2) # 2x3 matrix of 4s\n",
    "\n",
    "print(A.numpy())\n",
    "print(B.numpy())\n",
    "print(B0.numpy())\n",
    "print(B1.numpy())\n",
    "print(B2.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C1: [1 2 3 4]\n",
      "C23: [[1 2 3]\n",
      " [1 6 4]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import ones_like\n",
    "\n",
    "# Define tensors A1 and A23 as constants\n",
    "A1 = constant([1, 2, 3, 4])\n",
    "A23 = constant([[1, 2, 3], [1, 6, 4]])\n",
    "\n",
    "# Define B1 and B23 to have the correct shape\n",
    "B1 = ones_like(A1)\n",
    "B23 = ones_like(A23)\n",
    "\n",
    "# Perform element-wise multiplication\n",
    "C1 = multiply(A1,B1)\n",
    "C23 = multiply(A23,B23)\n",
    "\n",
    "# Print the tensors C1 and C23\n",
    "print('C1: {}'.format(C1.numpy()))\n",
    "print('C23: {}'.format(C23.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1687]\n",
      " [-3218]\n",
      " [-1933]\n",
      " [57850]]\n"
     ]
    }
   ],
   "source": [
    "# Define features, params, and bill as constants\n",
    "features = constant([[2, 24], [2, 26], [2, 57], [1, 37]])\n",
    "params = constant([[1000], [150]])\n",
    "bill = constant([[3913], [2682], [8617], [64400]])\n",
    "\n",
    "# Compute billpred using features and params\n",
    "billpred = matmul(features,params)\n",
    "\n",
    "# Compute and print the error\n",
    "error = bill - billpred\n",
    "print(error.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11 50]\n",
      " [ 7  2]\n",
      " [ 4 60]\n",
      " [ 3  0]\n",
      " [25 10]]\n",
      "172\n",
      "[ 50 122]\n",
      "[61  9 64  3 35]\n"
     ]
    }
   ],
   "source": [
    "wealth = constant([[11, 50], [7, 2], [4, 60], [3, 0],[25,10]])\n",
    "\n",
    "wealth_all = reduce_sum(wealth)\n",
    "# Sum over dimension 0,1\n",
    "wealth0 = reduce_sum(wealth,0) # 3x4 matrix of 2s\n",
    "wealth1 = reduce_sum(wealth,1) # 2x4 matrix of 3s\n",
    "\n",
    "\n",
    "print(wealth.numpy())\n",
    "print(wealth_all.numpy())\n",
    "print(wealth0.numpy())\n",
    "print(wealth1.numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Advanced operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gradient():         \n",
    "Computes the slope of a function at a point.       \n",
    "\n",
    "reshape():        \n",
    "Reshape a tensor (e.g. 10x10 to 100x1)         \n",
    "\n",
    "random():       \n",
    "Populates tensor with entries drawn.        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finding the optimum (gradient())**        \n",
    "\n",
    "In many ML problems, we will want to find the optimum of a funciton, e.g. minimise the loss function or maximise the objective function.        \n",
    "\n",
    "Minimum: lowest value of a loss function.          \n",
    "Maximum: highest value of objective function.           \n",
    "\n",
    "We can do this using the gradient() operation.      \n",
    "We start this process by passing points to the gradient operation until we find one where the gradient is 0, that is the **optimum**.        \n",
    "Minimum: change in gradient > 0.       \n",
    "Maximum: change in gradient < 0.          \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.0\n"
     ]
    }
   ],
   "source": [
    "# Define x\n",
    "x = tf.Variable(-1.0)\n",
    "\n",
    "# Define y to be x^2 wihtin instance of GradientTape\n",
    "# watch method to an instance of gradient tape and then pass the variable x,\n",
    "# this will allow us to compute the rate of change of y wrt x.\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(x)\n",
    "    y = tf.multiply(x,x)\n",
    "    \n",
    "# Evaluate the gradient of y at x = -1, using the tape instance of gradienttape\n",
    "g = tape.gradient(y,x)\n",
    "print(g.numpy())\n",
    "\n",
    "# slope is -2 at x = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Images as tensor (reshape())**        \n",
    "\n",
    "A grayscale image has a natural respresentation as matrix with values between 0 and 255. Some algorithm require us to reshape matrices into vectors before using them as inputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[221]\n",
      " [232]\n",
      " [206]\n",
      " [111]]\n",
      "[[105 109  38]\n",
      " [145 170 187]\n",
      " [ 94 225  87]\n",
      " [ 50 136 170]]\n"
     ]
    }
   ],
   "source": [
    "# generate grayscale image\n",
    "gray = tf.random.uniform([2,2],maxval=255, dtype=\"int32\")\n",
    "\n",
    "# reshape grayscale image\n",
    "gray = tf.reshape(gray, [2*2,1])\n",
    "\n",
    "print(gray.numpy())\n",
    "# generate a color image\n",
    "color = tf.random.uniform([2,2,3],maxval=255, dtype=\"int32\")\n",
    "\n",
    "# reshape color image\n",
    "color = tf.reshape(color,[2*2,3])\n",
    "print(color.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are given a loss function, y=x2, which you want to minimize. You can do this by computing the slope using the GradientTape() operation at different values of x. If the slope is positive, you can decrease the loss by lowering x. If it is negative, you can decrease it by increasing x. This is how gradient descent works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.0\n",
      "2.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "def compute_gradient(x0):\n",
    "  \t# Define x as a variable with an initial value of x0\n",
    "\tx = tf.Variable(x0)\n",
    "\twith tf.GradientTape() as tape:\n",
    "\t\ttape.watch(x)\n",
    "        # Define y using the multiply operation\n",
    "\t\ty = tf.multiply(x,x)\n",
    "    # Return the gradient of y with respect to x\n",
    "\treturn tape.gradient(y, x).numpy()\n",
    "\n",
    "# Compute and print gradients at x = -1, 1, and 0\n",
    "print(compute_gradient(-1.0))\n",
    "print(compute_gradient(1.0))\n",
    "print(compute_gradient(0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Linear Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Input data\n",
    "\n",
    "When we train a ML model, we will want to import data from an external source. Numeric data wil need to be assigned a type, and text and image data will need to be converted into a usable format.       \n",
    "\n",
    "External datasets can be imported using TensorFlow. It is useful for complex data pipeline. We can also use pandas to import data. And then we can convert data into numpy array, which we can use without further modification in TensorFlow.     \n",
    "Dataset will contain columns with different data types. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>...</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>7129300520</td>\n",
       "      <td>20141013T000000</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6414100192</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>2170</td>\n",
       "      <td>400</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5631500400</td>\n",
       "      <td>20150225T000000</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2487200875</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>910</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1954400510</td>\n",
       "      <td>20150218T000000</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id             date     price  bedrooms  bathrooms  sqft_living  \\\n",
       "0  7129300520  20141013T000000  221900.0         3       1.00         1180   \n",
       "1  6414100192  20141209T000000  538000.0         3       2.25         2570   \n",
       "2  5631500400  20150225T000000  180000.0         2       1.00          770   \n",
       "3  2487200875  20141209T000000  604000.0         4       3.00         1960   \n",
       "4  1954400510  20150218T000000  510000.0         3       2.00         1680   \n",
       "\n",
       "   sqft_lot  floors  waterfront  view  ...  grade  sqft_above  sqft_basement  \\\n",
       "0      5650     1.0           0     0  ...      7        1180              0   \n",
       "1      7242     2.0           0     0  ...      7        2170            400   \n",
       "2     10000     1.0           0     0  ...      6         770              0   \n",
       "3      5000     1.0           0     0  ...      7        1050            910   \n",
       "4      8080     1.0           0     0  ...      8        1680              0   \n",
       "\n",
       "   yr_built  yr_renovated  zipcode      lat     long  sqft_living15  \\\n",
       "0      1955             0    98178  47.5112 -122.257           1340   \n",
       "1      1951          1991    98125  47.7210 -122.319           1690   \n",
       "2      1933             0    98028  47.7379 -122.233           2720   \n",
       "3      1965             0    98136  47.5208 -122.393           1360   \n",
       "4      1987             0    98074  47.6168 -122.045           1800   \n",
       "\n",
       "   sqft_lot15  \n",
       "0        5650  \n",
       "1        7639  \n",
       "2        8062  \n",
       "3        5000  \n",
       "4        7503  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing = pd.read_csv(\"../Machine_Learning_basics/data/kc_house_data.csv\")\n",
    "housing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21613 entries, 0 to 21612\n",
      "Data columns (total 21 columns):\n",
      "id               21613 non-null int64\n",
      "date             21613 non-null object\n",
      "price            21613 non-null float64\n",
      "bedrooms         21613 non-null int64\n",
      "bathrooms        21613 non-null float64\n",
      "sqft_living      21613 non-null int64\n",
      "sqft_lot         21613 non-null int64\n",
      "floors           21613 non-null float64\n",
      "waterfront       21613 non-null int64\n",
      "view             21613 non-null int64\n",
      "condition        21613 non-null int64\n",
      "grade            21613 non-null int64\n",
      "sqft_above       21613 non-null int64\n",
      "sqft_basement    21613 non-null int64\n",
      "yr_built         21613 non-null int64\n",
      "yr_renovated     21613 non-null int64\n",
      "zipcode          21613 non-null int64\n",
      "lat              21613 non-null float64\n",
      "long             21613 non-null float64\n",
      "sqft_living15    21613 non-null int64\n",
      "sqft_lot15       21613 non-null int64\n",
      "dtypes: float64(5), int64(15), object(1)\n",
      "memory usage: 3.5+ MB\n"
     ]
    }
   ],
   "source": [
    "housing.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to numpy array\n",
    "housing_arr = np.array(housing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting data type with np array\n",
    "\n",
    "#convert price olumns to float32\n",
    "price = np.array(housing[\"price\"],np.float32)\n",
    "\n",
    "#convert waterfrount column to Boolean\n",
    "# waterfront is a np array after conversion\n",
    "waterfront = np.array(housing[\"waterfront\"], np.bool)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting data type using case in TensorFlow\n",
    "\n",
    "#convert price olumns to float32\n",
    "price = tf.cast(housing[\"price\"],tf.float32)\n",
    "\n",
    "#convert waterfrount column to Boolean\n",
    "# waterfront is tf.tensor type after conversion\n",
    "waterfront = tf.cast(housing[\"waterfront\"],tf.bool)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[221900. 538000. 180000. ... 402101. 400000. 325000.]\n",
      "tf.Tensor([False False False ... False False False], shape=(21613,), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "# Import numpy and tensorflow with their standard aliases\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Use a numpy array to define price as a 32-bit float\n",
    "price = np.array(housing['price'], np.float32)\n",
    "\n",
    "# Define waterfront as a Boolean using cast\n",
    "waterfront = tf.cast(housing['waterfront'], tf.bool)\n",
    "\n",
    "# Print price and waterfront\n",
    "print(price)\n",
    "print(waterfront)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Loss functions\n",
    "\n",
    "We need the loss funtion to train models because they tell us how well our model explains the data.     \n",
    "Measure of model fit: w/o this feedback, it is unclear how to adjust model parameters during the training process.     \n",
    "High loss value indicates that the model fit is poor: we typically want to minimise the loss function. (in some case we also might want to maximise a function instead). We can always place a minus sign before the function we want to maximize and instead minimise it.      \n",
    "\n",
    "TensorFlow has operations for common loss functions (for linear model):       \n",
    "1) Mean squared error (MSE)           \n",
    "2) Mean absolute error (MAE)        \n",
    "3) Huber error           \n",
    "\n",
    "Loss functions are accessible from tf.keras.losses():       \n",
    "tf.keras.losses.mse()         \n",
    "tf.keras.losses.mae()      \n",
    "tf.keras.losses.Huber()       \n",
    "\n",
    "MSE:       \n",
    "Strongly penalise outliers      \n",
    "High sensitivity near minimum       \n",
    "\n",
    "MAE:    \n",
    "Scales linearly with size of error      \n",
    "Low sensitity near minimum       \n",
    "\n",
    "Huber:    \n",
    "Similar to MSE near minimum      \n",
    "Similar to MAE away form minimum        \n",
    "\n",
    "For greater sensitivity near the minimum, use MSE or Huber.      \n",
    "To minimise the impact of outliers, use MAE or Huber.          \n",
    "\n",
    "In many cases, the training process will require us to supply a function that accepts our model's variables and ata and returns a loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a loss function\n",
    "\n",
    "# compute the MSE loss.\n",
    "# need two tensors to compute it: the actual values or target\n",
    "# predicted values or predictions\n",
    "\n",
    "loss = tf.keras.losses.mse(targets, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a linear regression model\n",
    "def linear_regression(intercept, slope = slope, features = features):\n",
    "    return intercept + features*slope\n",
    "\n",
    "# define a loss function ot compute the MSE\n",
    "def loss_function(intercept, slope, targets = targets, features = features):\n",
    "    # compute the predictions for a linear model\n",
    "    predictions = linear_regression(intercept, slope)\n",
    "    \n",
    "    # return the loss\n",
    "    return tf.keras.losses.mse(targets, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the loss for test data inputs\n",
    "loss_function(intercept, slope, test_targets, test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a variable named scalar\n",
    "scalar = tf.Variable(1.0, dtype=tf.float32)\n",
    "\n",
    "# Define the model\n",
    "def model(scalar, features = features):\n",
    "  \treturn scalar * features\n",
    "\n",
    "# Define a loss function\n",
    "def loss_function(scalar, features = features, targets = targets):\n",
    "\t# Compute the predicted values\n",
    "\tpredictions = model(scalar, features)\n",
    "    \n",
    "\t# Return the mean absolute error loss\n",
    "\treturn tf.keras.losses.mae(targets, predictions)\n",
    "\n",
    "# Evaluate the loss function and print the loss\n",
    "print(loss_function(scalar).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Linear Regression\n",
    "\n",
    "A linear regression model assumes a linear relationship (univariate regression):       \n",
    "price = intercept + size * slope + error (to predict house price with size of house)      \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "424840500000.0\n",
      "305881000000.0\n",
      "219757840000.0\n",
      "160266650000.0\n",
      "121212770000.0\n",
      "97023190000.0\n",
      "82984410000.0\n",
      "75397860000.0\n",
      "71600530000.0\n",
      "69847540000.0\n",
      "246.97383 253.7275\n"
     ]
    }
   ],
   "source": [
    "# Linear regression in TensorFlow\n",
    "\n",
    "# Define the targets and features\n",
    "price = np.array(housing[\"price\"],np.float32)\n",
    "size = np.array(housing[\"sqft_living\"],np.float32)\n",
    "\n",
    "# Define the intercept and slope, initialisation\n",
    "intercept = tf.Variable(0.1, dtype=np.float32)\n",
    "slope = tf.Variable(0.1, dtype=np.float32)\n",
    "\n",
    "# define a model: linear regression\n",
    "def linear_regression(intercept, slope, features = size):\n",
    "    return intercept + features*slope\n",
    "\n",
    "# compute the predicted and loss\n",
    "def loss_function(intercept, slope, targets = price, features = size):\n",
    "    predictions = linear_regression(intercept, slope)\n",
    "    return tf.keras.losses.mse(targets, predictions)\n",
    "\n",
    "# Define an optimisation operation\n",
    "# learning rate = 0.5\n",
    "opt = tf.keras.optimizers.Adam(0.5)\n",
    "\n",
    "# minimise the loss function and price the loss\n",
    "for j in range(1000):\n",
    "    opt.minimize(lambda: loss_function(intercept,slope), var_list=[intercept,slope])\n",
    "    if j % 100 == 0:\n",
    "\t    print(loss_function(intercept, slope).numpy())\n",
    "    \n",
    "# print the trained parameter\n",
    "print(intercept.numpy(), slope.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Batch training\n",
    "\n",
    "We can use batch training to handle large datasets.        \n",
    "\n",
    "If the dataset is much larger and we cannot fit the entire dataset in memory, we can instead divide it into batchs and train on those batches sequentially.        \n",
    "\n",
    "A single pass over all of the batch is called an epoch and the process itself is called batch training.      \n",
    "Batch trianing also allow us to update model weights and optimizer parameters after each batch, rather than at the end of the epoch.       \n",
    "\n",
    "pd.read_csv() allows us to load data in batches.      \n",
    "Avoid loading entire dataset.     \n",
    "We can do this by using the chunksize parameter to provide batch size.         \n",
    "\n",
    "Full sample:       \n",
    "1) One update per epoch         \n",
    "2) Accepts datasets w/o modification       \n",
    "3) Limited by memory      \n",
    "\n",
    "Batch Training:       \n",
    "1) Multiple updates per epoch       \n",
    "2) Requires division of dataset      \n",
    "3) No limit on dataset size          \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data in batches\n",
    "\n",
    "for batch in pd.read_csv(\"../Machine_Learning_basics/data/kc_house_data.csv\", chunksize=100):\n",
    "    #extract price column\n",
    "    price = np.array(batch[\"price\"],np.float32)\n",
    "    \n",
    "    #extract size column\n",
    "    size = np.array(batch[\"size\"],np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.31781912 0.29831016\n"
     ]
    }
   ],
   "source": [
    "# train a linear model in batches, minimumal example\n",
    "\n",
    "# Define trainable variable\n",
    "intercept = tf.Variable(0.1, dtype=np.float32)\n",
    "slope = tf.Variable(0.1,dtype=np.float32)\n",
    "\n",
    "# Define model\n",
    "def linear_regression(intercept, slope, features):\n",
    "    return intercept + features*slope\n",
    "\n",
    "# Compute predicted values and return loss function\n",
    "def loss_function(intercept, slope,targets,features):\n",
    "    predictions = linear_regression(intercept,slope,features)\n",
    "    return tf.keras.losses.mse(targets,predictions)\n",
    "\n",
    "# Define optimizer\n",
    "opt = tf.keras.optimizers.Adam()\n",
    "\n",
    "# load data in batches\n",
    "for batch in pd.read_csv(\"../Machine_Learning_basics/data/kc_house_data.csv\", chunksize=100):\n",
    "    #extract the target and feature columns\n",
    "    price_batch = np.array(batch[\"price\"],np.float32)\n",
    "    size_batch = np.array(batch[\"sqft_lot\"],np.float32)\n",
    "    \n",
    "    #minimize the loss function\n",
    "    opt.minimize(lambda: loss_function(intercept, slope, price_batch, size_batch),var_list=[intercept,slope])\n",
    "    \n",
    "print(intercept.numpy(),slope.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
